{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_                                                                        Ilja Surikovs_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Jupyter notebook for the case study (using Python 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the necessary libraries: \n",
    "* Pandas package to efficiently work with DataFrames\n",
    "* NumPy package for math / linear algebra\n",
    "* Datetime to work with date/time data\n",
    "* StandardScaler to normalize the data\n",
    "* LogisticRegression - ML-model to determine key factors in Task 2\n",
    "* RandomForestClassifier - ML-model for predictions in Task 3\n",
    "* Train_test_split - to split data in training and test set\n",
    "* cros_val_score to perform cross-validation when optimizing the models\n",
    "* GridSearchCV - to perform Grid Search to find optimal hyperparameters for ML-models\n",
    "* matplotlib (plt and mpath) for visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path as mpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to show graphs inside of the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_1) Setup_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining dataset names. Can change names to add other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_dataset_0 = 'app_dataset.csv'\n",
    "name_dataset_1 = 'dataset_1.csv'\n",
    "name_dataset_2 = 'dataset_2.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining key names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key1 = 'key1'\n",
    "key2 = 'key2'\n",
    "key_names = [key1, key2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading CSV-fomratted datasets as Pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_0 = pd.read_csv(name_dataset_0, sep=';')\n",
    "dataset_1 = pd.read_csv(name_dataset_1, sep=';')\n",
    "dataset_2 = pd.read_csv(name_dataset_2, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_2) Investigating the datasets - checking how many rows, columns and elements they have_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function to print the number of columns, rows and elements for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_col_row_and_cell_count(df):\n",
    "    row_count, column_count = df.shape\n",
    "    element_count = column_count*row_count\n",
    "    print('column count:  ', column_count)\n",
    "    print('row count:     ', row_count)\n",
    "    print('element count: ', element_count)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total number of row and column count for each dataset (including NA values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) dataset 0\n",
      "column count:   5\n",
      "row count:      798\n",
      "element count:  3990\n",
      "\n",
      "2) dataset 1\n",
      "column count:   169\n",
      "row count:      14571\n",
      "element count:  2462499\n",
      "\n",
      "3) dataset 2\n",
      "column count:   37\n",
      "row count:      10137\n",
      "element count:  375069\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('1) dataset 0')\n",
    "print_col_row_and_cell_count(dataset_0)\n",
    "print('2) dataset 1')\n",
    "print_col_row_and_cell_count(dataset_1)\n",
    "print('3) dataset 2')\n",
    "print_col_row_and_cell_count(dataset_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_3) Joining the datasets_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_0_and_1 = pd.merge(dataset_0, dataset_1, how='left', on=key2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_not_cleaned = pd.merge(dataset_0_and_1, dataset_2, how='left', on=key1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_full - before cleaning NAs\n",
      "column count:   209\n",
      "row count:      798\n",
      "element count:  166782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('dataset_full - before cleaning NAs')\n",
    "print_col_row_and_cell_count(dataset_full_not_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_4) Dropping columns with keys. Removing columns and rows containing many NA values. Saving the final dateset to CSV file_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the join is done, keys are not needed. Dropping them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_not_cleaned_keys_dropped = dataset_full_not_cleaned.drop(key_names, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to deal with NA values. It will drop rows and columns if the amount of non-NA values in a given column or row is below a given threshold. By default it is 20% for columns and 5% for rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_rows_and_cols_with_NA_below_thresholds(input_df, key_names=key_names, col_thresh=0.20, row_thresh=0.05):\n",
    "    df = input_df.copy(deep=True)\n",
    "    \n",
    "    number_of_cols = len(list(df.columns))\n",
    "    row_threshold_integer = round(row_thresh * number_of_cols)\n",
    "    df = df.dropna(axis=0, thresh=row_threshold_integer) # droping rows that have non-NA cell count below threshold\n",
    "    \n",
    "    number_of_rows = len(df)\n",
    "    col_threshold_integer = round(col_thresh * number_of_rows)\n",
    "    output_df = df.dropna(axis=1, thresh=col_threshold_integer).loc[:] # droping columns that have non-NA cell count below threshold\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_clean = drop_rows_and_cols_with_NA_below_thresholds(dataset_full_not_cleaned_keys_dropped, \n",
    "                                                                 col_thresh=0.20, row_thresh=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_full_clean - after some columns and rows with many missing values are removed\n",
      "column count:   60\n",
      "row count:      772\n",
      "element count:  46320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('dataset_full_clean - after some columns and rows with many missing values are removed')\n",
    "print_col_row_and_cell_count(dataset_full_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will define functions to calculate number of Nulls in a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_nulls_in_col(col):\n",
    "    if col.dtype=='O':\n",
    "        null_count_in_col = len(col[pd.isnull(col)])\n",
    "        empty_count_in_col = len(col[col==''])\n",
    "        null_count_in_col = null_count_in_col + empty_count_in_col\n",
    "    else:\n",
    "        null_count_in_col = len(col[np.isnan(col)])\n",
    "    return null_count_in_col\n",
    "\n",
    "def count_nulls_in_df(df):\n",
    "    null_counts_in_cols = df.apply(count_nulls_in_col)\n",
    "    null_count_in_df = null_counts_in_cols.sum()\n",
    "    return null_count_in_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of Nulls in the dataset: 17473\n"
     ]
    }
   ],
   "source": [
    "print('number of Nulls in the dataset:', count_nulls_in_df(dataset_full_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the final dataset as a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_clean.to_csv('output_dataset_full_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_5) Observations on data integrity _**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, we see that a lot of data is not used. In the final table we have 772 rows (there were 798 rows in the 'master' dataset_0). Dataset1 has 14571 rows, and dataset2 - 10137. Since response variable is available only in 798 rows in the master dataset, we have to ignore most of the rows from dataset1 and dataset2. \n",
    "\n",
    "On top of that, there are a lot of missing values (NA), especially in the dataset1. The combined dataset has 209 columns, before the columns with many NAs are removed. After I remove them, applying 20% threshold, only 60 columns remain. The final dataset has 46 320 elements out which 17 473 are Nulls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_1) Setup_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to clean the dataset and to make various transformations before performing any analysis on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Defining the name of the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = 'response'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Defining function to get all column names except for the target and key columns. Will allow to dynamically analyze dataframes without the need to know exact columns they have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_col_names_without_target(dataframe, target = target):\n",
    "    column_names_list = list(dataframe.columns)\n",
    "    if target in column_names_list:\n",
    "        column_names_list.remove(target)\n",
    "    return column_names_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) We want to determine which factors are the most important in predicting target variable (response). Many variables still has too many NAs, so I will use more agressive column threshold (60%) to remove columns/factors with many missing values. Otherwise, we would introduce too much bias if we would try to impute them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column count:   38\n",
      "row count:      772\n",
      "element count:  29336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_full = drop_rows_and_cols_with_NA_below_thresholds(dataset_full_clean, col_thresh=0.60, row_thresh=0.05)\n",
    "print_col_row_and_cell_count(dataset_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) i. Python uses '.' as a decimal point. However, in datasets sometimes we get ',' as a decimal point. Need to replace ',' with '.'. ii. I will replace all '+' and '_' with ' ' and convert all string to lower case, that would help to allign string formatting and reduce some noise in the data. iii. After this is done, will need to convert floats stored as string to Python floats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_commas_with_dots_in_string(single_string):\n",
    "    if type(single_string) == str:\n",
    "        single_string = single_string.replace(',','.')\n",
    "    return single_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# applying a function on each cell of a dataframe\n",
    "dataset_full = dataset_full.applymap(replace_commas_with_dots_in_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_spec_chars_with_space_in_string(single_string):\n",
    "    if type(single_string) == str:\n",
    "        single_string = single_string.replace('+',' ')\n",
    "        single_string = single_string.replace('_',' ')\n",
    "    return single_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full = dataset_full.applymap(replace_spec_chars_with_space_in_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strings_to_lower_case(col):\n",
    "    if col.dtype=='O':\n",
    "        col = col.str.lower()\n",
    "    return col        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full = dataset_full.apply(strings_to_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to convert floats stored as string to floats\n",
    "def convert_floats_in_string_to_floats(element):\n",
    "    if type(element) == str:\n",
    "        try:\n",
    "            return float(element)\n",
    "        except (ValueError, TypeError):\n",
    "            return element\n",
    "    return element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full = dataset_full.applymap(convert_floats_in_string_to_floats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "(e) Some columns might contain dates in string format. I will convert those to floats. It is done by firstly converting string dates to datetime format. Then from those datetimes I substract epoch date (1 jan 1970) and convert it to seconds, which is in float format. Essentially, each cell with a date after the transformation will show how many seconds has passed after 1 jan 1970 till this cell's initial date. This number is in float, so ML algorithms (logistic regression, random forest classifier, etc) can be applied on it.\n",
    "\n",
    "The function below will do this transformation. It is a vectorized function, so it is efficient. Also, it will convert only those columns, that initially contain dates in string, otherwise it will not change the columns. Thus, it is very general and would work on various datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def string_dates_to_sec_after_epoch_as_float(input_col):\n",
    "    if input_col.dtype=='O': #in pandas dataframe columns containing Strings, has type Object, or 'O'\n",
    "        col_datetime=pd.to_datetime(input_col, format='%Y-%m-%d %H:%M', errors='ignore') #convert to datetime only if format is '%Y-%m-%d %H:%M'\n",
    "        if col_datetime.dtype=='datetime64[ns]': \n",
    "            epoch_timestamp_col = col_datetime - dt.datetime(1970, 1, 1)\n",
    "            sec_float_col = epoch_timestamp_col / np.timedelta64(1, 's')\n",
    "            return sec_float_col\n",
    "        return col_datetime\n",
    "    else:\n",
    "        return input_col           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_time_converted = dataset_full.apply(string_dates_to_sec_after_epoch_as_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) We have converted string columns that contain dates and floats. Now, the remaining columns with string (text) contain only categorical variables (e.g. 'big', 'small' and 'medium'). We need to convert this information to numerical data. I will do it by  creating a binary variable for each category. Binary variable (dummy) being 1 means that a given record belongs to a given category, and 0 indicates that it does not belong. If the value is missing, then a new category ('missing') is created. The initial column with strings is dropped. For example, column B contains 'yes', 'no' and 'N/A', then column B is dropped, and 3 new columns are created: B_yes, B_no and B_NA.\n",
    "However, it might be not optimal to create too many binary columns for 1 column. If the number of unique categories in one string column is over a specified threshold, then I will drop it. For that, I will define a function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_string_cols_with_unique_value_count_over_threshold(input_df, unique_count_threshold = 50):\n",
    "    df = input_df.copy(deep=True)\n",
    "    unique_counts_in_string_cols_series = df.select_dtypes(include=[object]).nunique() #string is 'object' type\n",
    "    string_cols_over_threshold_series = unique_counts_in_string_cols_series[unique_counts_in_string_cols_series>unique_count_threshold]\n",
    "    list_of_string_cols_over_threshold = list(string_cols_over_threshold_series.keys())\n",
    "    df = df.drop(list_of_string_cols_over_threshold, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(772, 38)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_full_time_converted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_with_some_string_cols_removed = remove_string_cols_with_unique_value_count_over_threshold(\n",
    "    input_df = dataset_full_time_converted, unique_count_threshold = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(772, 37)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_full_with_some_string_cols_removed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dummies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_with_dummies = pd.get_dummies(dataset_full_with_some_string_cols_removed, dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_with_dummies.to_csv('out_dataset_full_with_dummies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(g) Imputing remaining missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still many missing values. In order to use Machine Learning models in Task 2 and 3, I need to remove or impute missing values (NAs). In the previous parts I have removed some. The remaining will be imputed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am imputing missing values with a median value for each feature, as it is less biased than mean (outliers have a significant impact on mean, but not on median)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_filled = dataset_full_with_dummies.fillna(dataset_full_with_dummies.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(h) I need to normalize the data - it will make coefficients comparable. It is also a necessary condition for regularization. And in general, normalized data is preferred in ML-algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#saving target column separately, as it should not be transformed (we need 1 and 0 for classification)\n",
    "y = pd.DataFrame(dataset_filled[target].values)\n",
    "predictors = get_col_names_without_target(dataset_filled)\n",
    "\n",
    "scaler = StandardScaler() #creating an instance fo StandardScaler\n",
    "scaler.fit(dataset_filled[predictors]) #normalizing only predictors\n",
    "dataset_normalized_np_array = scaler.transform(dataset_filled[predictors].values) #creating numpy dataframe\n",
    "dataset_normalized = pd.DataFrame(dataset_normalized_np_array, columns=predictors) #converting numpy to pandas dataframe. Adding columns\n",
    "dataset_normalized[target] = y #adding target back\n",
    "dataset_normalized = dataset_normalized[[target] + predictors] #for convenience putting target as a first column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_2) Looking at correlations_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating a correlation matrix between target and all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>v001</th>\n",
       "      <th>v002</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v14</th>\n",
       "      <th>v29</th>\n",
       "      <th>v120</th>\n",
       "      <th>v123</th>\n",
       "      <th>v173</th>\n",
       "      <th>...</th>\n",
       "      <th>v204_mobile</th>\n",
       "      <th>v204_residential</th>\n",
       "      <th>v204_wifi</th>\n",
       "      <th>v204_wired</th>\n",
       "      <th>v204_nan</th>\n",
       "      <th>v172.1_n</th>\n",
       "      <th>v172.1_p</th>\n",
       "      <th>v172.1_u</th>\n",
       "      <th>v172.1_y</th>\n",
       "      <th>v172.1_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>response</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>-0.072353</td>\n",
       "      <td>-0.007668</td>\n",
       "      <td>-0.013845</td>\n",
       "      <td>-0.017492</td>\n",
       "      <td>-0.172579</td>\n",
       "      <td>0.051613</td>\n",
       "      <td>0.001951</td>\n",
       "      <td>0.042317</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024923</td>\n",
       "      <td>0.077241</td>\n",
       "      <td>-0.148913</td>\n",
       "      <td>-0.002650</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>-0.045414</td>\n",
       "      <td>-0.010143</td>\n",
       "      <td>0.009589</td>\n",
       "      <td>-0.032629</td>\n",
       "      <td>0.010840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v001</th>\n",
       "      <td>0.016594</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.028172</td>\n",
       "      <td>0.026159</td>\n",
       "      <td>0.042749</td>\n",
       "      <td>0.026423</td>\n",
       "      <td>-0.042262</td>\n",
       "      <td>0.062640</td>\n",
       "      <td>0.065808</td>\n",
       "      <td>-0.023079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021698</td>\n",
       "      <td>0.017588</td>\n",
       "      <td>-0.037195</td>\n",
       "      <td>-0.082489</td>\n",
       "      <td>0.053279</td>\n",
       "      <td>0.018721</td>\n",
       "      <td>0.039101</td>\n",
       "      <td>-0.055188</td>\n",
       "      <td>-0.057636</td>\n",
       "      <td>0.060728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v002</th>\n",
       "      <td>-0.072353</td>\n",
       "      <td>-0.028172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.161154</td>\n",
       "      <td>0.089772</td>\n",
       "      <td>0.156599</td>\n",
       "      <td>0.150948</td>\n",
       "      <td>-0.019944</td>\n",
       "      <td>0.015985</td>\n",
       "      <td>0.056365</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010204</td>\n",
       "      <td>-0.090875</td>\n",
       "      <td>0.104379</td>\n",
       "      <td>0.067423</td>\n",
       "      <td>0.046851</td>\n",
       "      <td>-0.035833</td>\n",
       "      <td>-0.040280</td>\n",
       "      <td>-0.022865</td>\n",
       "      <td>0.002458</td>\n",
       "      <td>0.039053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v4</th>\n",
       "      <td>-0.007668</td>\n",
       "      <td>0.026159</td>\n",
       "      <td>0.161154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.738650</td>\n",
       "      <td>0.985423</td>\n",
       "      <td>0.302075</td>\n",
       "      <td>0.209135</td>\n",
       "      <td>0.277026</td>\n",
       "      <td>0.010641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016620</td>\n",
       "      <td>-0.061750</td>\n",
       "      <td>0.043348</td>\n",
       "      <td>-0.044838</td>\n",
       "      <td>0.061015</td>\n",
       "      <td>-0.023792</td>\n",
       "      <td>-0.031783</td>\n",
       "      <td>-0.048033</td>\n",
       "      <td>-0.000563</td>\n",
       "      <td>0.061561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v5</th>\n",
       "      <td>-0.013845</td>\n",
       "      <td>0.042749</td>\n",
       "      <td>0.089772</td>\n",
       "      <td>0.738650</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.739335</td>\n",
       "      <td>0.312050</td>\n",
       "      <td>0.329635</td>\n",
       "      <td>0.383194</td>\n",
       "      <td>0.022785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017533</td>\n",
       "      <td>-0.120228</td>\n",
       "      <td>0.070998</td>\n",
       "      <td>-0.036415</td>\n",
       "      <td>0.075617</td>\n",
       "      <td>-0.008706</td>\n",
       "      <td>-0.048088</td>\n",
       "      <td>-0.061443</td>\n",
       "      <td>-0.012874</td>\n",
       "      <td>0.079078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v14</th>\n",
       "      <td>-0.017492</td>\n",
       "      <td>0.026423</td>\n",
       "      <td>0.156599</td>\n",
       "      <td>0.985423</td>\n",
       "      <td>0.739335</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.303795</td>\n",
       "      <td>0.225246</td>\n",
       "      <td>0.289810</td>\n",
       "      <td>0.016430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019737</td>\n",
       "      <td>-0.059451</td>\n",
       "      <td>0.048794</td>\n",
       "      <td>-0.043985</td>\n",
       "      <td>0.051670</td>\n",
       "      <td>-0.023801</td>\n",
       "      <td>-0.032463</td>\n",
       "      <td>-0.039713</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.052564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v29</th>\n",
       "      <td>-0.172579</td>\n",
       "      <td>-0.042262</td>\n",
       "      <td>0.150948</td>\n",
       "      <td>0.302075</td>\n",
       "      <td>0.312050</td>\n",
       "      <td>0.303795</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.157450</td>\n",
       "      <td>0.163382</td>\n",
       "      <td>0.058766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033399</td>\n",
       "      <td>-0.048993</td>\n",
       "      <td>0.101896</td>\n",
       "      <td>0.056682</td>\n",
       "      <td>-0.012713</td>\n",
       "      <td>-0.013708</td>\n",
       "      <td>-0.061391</td>\n",
       "      <td>0.019671</td>\n",
       "      <td>0.023207</td>\n",
       "      <td>-0.010858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v120</th>\n",
       "      <td>0.051613</td>\n",
       "      <td>0.062640</td>\n",
       "      <td>-0.019944</td>\n",
       "      <td>0.209135</td>\n",
       "      <td>0.329635</td>\n",
       "      <td>0.225246</td>\n",
       "      <td>0.157450</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.733878</td>\n",
       "      <td>0.017526</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030635</td>\n",
       "      <td>-0.050454</td>\n",
       "      <td>-0.033850</td>\n",
       "      <td>-0.037192</td>\n",
       "      <td>0.143450</td>\n",
       "      <td>-0.024368</td>\n",
       "      <td>-0.015127</td>\n",
       "      <td>-0.134820</td>\n",
       "      <td>0.006430</td>\n",
       "      <td>0.145945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v123</th>\n",
       "      <td>0.001951</td>\n",
       "      <td>0.065808</td>\n",
       "      <td>0.015985</td>\n",
       "      <td>0.277026</td>\n",
       "      <td>0.383194</td>\n",
       "      <td>0.289810</td>\n",
       "      <td>0.163382</td>\n",
       "      <td>0.733878</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.051716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>-0.049136</td>\n",
       "      <td>0.017068</td>\n",
       "      <td>-0.029950</td>\n",
       "      <td>0.063949</td>\n",
       "      <td>-0.018716</td>\n",
       "      <td>-0.016883</td>\n",
       "      <td>-0.055532</td>\n",
       "      <td>-0.007136</td>\n",
       "      <td>0.066902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v173</th>\n",
       "      <td>0.042317</td>\n",
       "      <td>-0.023079</td>\n",
       "      <td>0.056365</td>\n",
       "      <td>0.010641</td>\n",
       "      <td>0.022785</td>\n",
       "      <td>0.016430</td>\n",
       "      <td>0.058766</td>\n",
       "      <td>0.017526</td>\n",
       "      <td>0.051716</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017673</td>\n",
       "      <td>-0.099213</td>\n",
       "      <td>0.031243</td>\n",
       "      <td>0.045614</td>\n",
       "      <td>0.059518</td>\n",
       "      <td>-0.074746</td>\n",
       "      <td>-0.059899</td>\n",
       "      <td>-0.015655</td>\n",
       "      <td>-0.058134</td>\n",
       "      <td>0.060699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v174</th>\n",
       "      <td>-0.044762</td>\n",
       "      <td>0.023308</td>\n",
       "      <td>-0.054430</td>\n",
       "      <td>-0.009915</td>\n",
       "      <td>-0.020723</td>\n",
       "      <td>-0.015724</td>\n",
       "      <td>-0.056870</td>\n",
       "      <td>-0.016925</td>\n",
       "      <td>-0.050899</td>\n",
       "      <td>-0.999832</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011385</td>\n",
       "      <td>0.086854</td>\n",
       "      <td>-0.025317</td>\n",
       "      <td>-0.042905</td>\n",
       "      <td>-0.055338</td>\n",
       "      <td>0.074804</td>\n",
       "      <td>0.058405</td>\n",
       "      <td>0.011945</td>\n",
       "      <td>0.057632</td>\n",
       "      <td>-0.056421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v175</th>\n",
       "      <td>0.016363</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>0.036745</td>\n",
       "      <td>0.022826</td>\n",
       "      <td>0.022109</td>\n",
       "      <td>0.020325</td>\n",
       "      <td>-0.002560</td>\n",
       "      <td>0.011377</td>\n",
       "      <td>0.010423</td>\n",
       "      <td>0.096303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009334</td>\n",
       "      <td>-0.098594</td>\n",
       "      <td>-0.037143</td>\n",
       "      <td>-0.022360</td>\n",
       "      <td>0.165227</td>\n",
       "      <td>-0.215025</td>\n",
       "      <td>-0.271529</td>\n",
       "      <td>0.040504</td>\n",
       "      <td>-0.369961</td>\n",
       "      <td>0.163113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v176</th>\n",
       "      <td>-0.019849</td>\n",
       "      <td>-0.002542</td>\n",
       "      <td>-0.034321</td>\n",
       "      <td>-0.022698</td>\n",
       "      <td>-0.020502</td>\n",
       "      <td>-0.020099</td>\n",
       "      <td>0.005673</td>\n",
       "      <td>-0.012557</td>\n",
       "      <td>-0.010168</td>\n",
       "      <td>-0.094509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.084703</td>\n",
       "      <td>0.050265</td>\n",
       "      <td>0.028594</td>\n",
       "      <td>-0.173165</td>\n",
       "      <td>0.215696</td>\n",
       "      <td>0.269962</td>\n",
       "      <td>-0.032460</td>\n",
       "      <td>0.369446</td>\n",
       "      <td>-0.171096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v177</th>\n",
       "      <td>0.048428</td>\n",
       "      <td>-0.002857</td>\n",
       "      <td>-0.021130</td>\n",
       "      <td>0.009787</td>\n",
       "      <td>0.030602</td>\n",
       "      <td>0.006996</td>\n",
       "      <td>-0.045187</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>-0.001916</td>\n",
       "      <td>-0.069621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040159</td>\n",
       "      <td>-0.023157</td>\n",
       "      <td>-0.060555</td>\n",
       "      <td>-0.029300</td>\n",
       "      <td>0.121614</td>\n",
       "      <td>-0.150750</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>-0.030689</td>\n",
       "      <td>-0.217245</td>\n",
       "      <td>0.120156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v180</th>\n",
       "      <td>0.022540</td>\n",
       "      <td>0.034855</td>\n",
       "      <td>0.036069</td>\n",
       "      <td>0.018493</td>\n",
       "      <td>0.031174</td>\n",
       "      <td>0.016046</td>\n",
       "      <td>-0.021656</td>\n",
       "      <td>0.013454</td>\n",
       "      <td>-0.003963</td>\n",
       "      <td>0.065332</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023473</td>\n",
       "      <td>-0.132832</td>\n",
       "      <td>-0.054981</td>\n",
       "      <td>-0.029743</td>\n",
       "      <td>0.227068</td>\n",
       "      <td>-0.170986</td>\n",
       "      <td>-0.175666</td>\n",
       "      <td>-0.053170</td>\n",
       "      <td>-0.348206</td>\n",
       "      <td>0.224360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v181</th>\n",
       "      <td>0.026332</td>\n",
       "      <td>-0.013670</td>\n",
       "      <td>0.046281</td>\n",
       "      <td>0.040124</td>\n",
       "      <td>0.032608</td>\n",
       "      <td>0.042488</td>\n",
       "      <td>0.034544</td>\n",
       "      <td>-0.011165</td>\n",
       "      <td>-0.008010</td>\n",
       "      <td>0.096625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103508</td>\n",
       "      <td>-0.010617</td>\n",
       "      <td>0.010018</td>\n",
       "      <td>0.099824</td>\n",
       "      <td>-0.140203</td>\n",
       "      <td>-0.053073</td>\n",
       "      <td>-0.053073</td>\n",
       "      <td>0.163087</td>\n",
       "      <td>-0.027995</td>\n",
       "      <td>-0.138417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v182</th>\n",
       "      <td>0.066963</td>\n",
       "      <td>0.027891</td>\n",
       "      <td>0.049610</td>\n",
       "      <td>-0.013755</td>\n",
       "      <td>0.037750</td>\n",
       "      <td>-0.017427</td>\n",
       "      <td>0.010566</td>\n",
       "      <td>0.037434</td>\n",
       "      <td>0.028961</td>\n",
       "      <td>0.514751</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117849</td>\n",
       "      <td>-0.152248</td>\n",
       "      <td>-0.138372</td>\n",
       "      <td>-0.071711</td>\n",
       "      <td>0.435554</td>\n",
       "      <td>-0.054048</td>\n",
       "      <td>-0.085544</td>\n",
       "      <td>-0.364803</td>\n",
       "      <td>-0.108406</td>\n",
       "      <td>0.436544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v183</th>\n",
       "      <td>0.021228</td>\n",
       "      <td>0.031512</td>\n",
       "      <td>0.023708</td>\n",
       "      <td>-0.007962</td>\n",
       "      <td>-0.008904</td>\n",
       "      <td>-0.009189</td>\n",
       "      <td>-0.039029</td>\n",
       "      <td>-0.008797</td>\n",
       "      <td>-0.017028</td>\n",
       "      <td>0.052509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023692</td>\n",
       "      <td>-0.101339</td>\n",
       "      <td>-0.016571</td>\n",
       "      <td>0.034264</td>\n",
       "      <td>0.093479</td>\n",
       "      <td>-0.075338</td>\n",
       "      <td>-0.075338</td>\n",
       "      <td>-0.017642</td>\n",
       "      <td>-0.152879</td>\n",
       "      <td>0.092288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v185</th>\n",
       "      <td>0.018609</td>\n",
       "      <td>0.032782</td>\n",
       "      <td>0.030687</td>\n",
       "      <td>0.016085</td>\n",
       "      <td>0.026678</td>\n",
       "      <td>0.013559</td>\n",
       "      <td>-0.022860</td>\n",
       "      <td>0.010256</td>\n",
       "      <td>-0.006240</td>\n",
       "      <td>0.057240</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023946</td>\n",
       "      <td>-0.124233</td>\n",
       "      <td>-0.055139</td>\n",
       "      <td>-0.017898</td>\n",
       "      <td>0.214553</td>\n",
       "      <td>-0.162560</td>\n",
       "      <td>-0.190442</td>\n",
       "      <td>-0.041469</td>\n",
       "      <td>-0.341731</td>\n",
       "      <td>0.211820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v191</th>\n",
       "      <td>0.194025</td>\n",
       "      <td>-0.026984</td>\n",
       "      <td>-0.011798</td>\n",
       "      <td>-0.017876</td>\n",
       "      <td>-0.017656</td>\n",
       "      <td>-0.013643</td>\n",
       "      <td>-0.074641</td>\n",
       "      <td>-0.006081</td>\n",
       "      <td>0.005703</td>\n",
       "      <td>-0.004563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.070954</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.018522</td>\n",
       "      <td>-0.122082</td>\n",
       "      <td>-0.018557</td>\n",
       "      <td>-0.018557</td>\n",
       "      <td>0.130693</td>\n",
       "      <td>-0.024377</td>\n",
       "      <td>-0.120527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v192</th>\n",
       "      <td>0.194025</td>\n",
       "      <td>-0.026984</td>\n",
       "      <td>-0.011798</td>\n",
       "      <td>-0.017876</td>\n",
       "      <td>-0.017656</td>\n",
       "      <td>-0.013643</td>\n",
       "      <td>-0.074641</td>\n",
       "      <td>-0.006081</td>\n",
       "      <td>0.005703</td>\n",
       "      <td>-0.004563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.070954</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.018522</td>\n",
       "      <td>-0.122082</td>\n",
       "      <td>-0.018557</td>\n",
       "      <td>-0.018557</td>\n",
       "      <td>0.130693</td>\n",
       "      <td>-0.024377</td>\n",
       "      <td>-0.120527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v196</th>\n",
       "      <td>0.034318</td>\n",
       "      <td>-0.003731</td>\n",
       "      <td>-0.003506</td>\n",
       "      <td>0.004440</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>0.003290</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>-0.014796</td>\n",
       "      <td>-0.011881</td>\n",
       "      <td>0.229137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037737</td>\n",
       "      <td>-0.002411</td>\n",
       "      <td>0.063331</td>\n",
       "      <td>-0.026424</td>\n",
       "      <td>-0.072091</td>\n",
       "      <td>-0.010958</td>\n",
       "      <td>-0.010958</td>\n",
       "      <td>0.077176</td>\n",
       "      <td>-0.014395</td>\n",
       "      <td>-0.071173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v197</th>\n",
       "      <td>0.034318</td>\n",
       "      <td>-0.003731</td>\n",
       "      <td>-0.003506</td>\n",
       "      <td>0.004440</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>0.003290</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>-0.014796</td>\n",
       "      <td>-0.011881</td>\n",
       "      <td>0.229137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037737</td>\n",
       "      <td>-0.002411</td>\n",
       "      <td>0.063331</td>\n",
       "      <td>-0.026424</td>\n",
       "      <td>-0.072091</td>\n",
       "      <td>-0.010958</td>\n",
       "      <td>-0.010958</td>\n",
       "      <td>0.077176</td>\n",
       "      <td>-0.014395</td>\n",
       "      <td>-0.071173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v198</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v200</th>\n",
       "      <td>0.029653</td>\n",
       "      <td>0.030867</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>-0.013900</td>\n",
       "      <td>0.011399</td>\n",
       "      <td>-0.011734</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.007363</td>\n",
       "      <td>0.009828</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028754</td>\n",
       "      <td>0.032062</td>\n",
       "      <td>0.029781</td>\n",
       "      <td>0.014407</td>\n",
       "      <td>-0.099252</td>\n",
       "      <td>0.005975</td>\n",
       "      <td>0.005975</td>\n",
       "      <td>-0.042078</td>\n",
       "      <td>0.007848</td>\n",
       "      <td>0.038805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v178_certified</th>\n",
       "      <td>-0.024196</td>\n",
       "      <td>0.020057</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>-0.007672</td>\n",
       "      <td>0.023338</td>\n",
       "      <td>-0.007340</td>\n",
       "      <td>-0.024240</td>\n",
       "      <td>-0.011752</td>\n",
       "      <td>-0.014852</td>\n",
       "      <td>-0.085115</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023462</td>\n",
       "      <td>-0.026161</td>\n",
       "      <td>-0.024300</td>\n",
       "      <td>-0.011756</td>\n",
       "      <td>-0.032072</td>\n",
       "      <td>0.263955</td>\n",
       "      <td>0.263955</td>\n",
       "      <td>-0.075650</td>\n",
       "      <td>-0.006404</td>\n",
       "      <td>-0.031664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v178_emailinexistent</th>\n",
       "      <td>0.012306</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>0.012175</td>\n",
       "      <td>-0.018744</td>\n",
       "      <td>-0.036280</td>\n",
       "      <td>-0.018398</td>\n",
       "      <td>-0.034325</td>\n",
       "      <td>-0.019692</td>\n",
       "      <td>-0.013774</td>\n",
       "      <td>0.039195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061771</td>\n",
       "      <td>-0.037046</td>\n",
       "      <td>0.012032</td>\n",
       "      <td>0.065733</td>\n",
       "      <td>-0.045416</td>\n",
       "      <td>-0.006903</td>\n",
       "      <td>-0.006903</td>\n",
       "      <td>0.048620</td>\n",
       "      <td>-0.009068</td>\n",
       "      <td>-0.044837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v178_validdomain</th>\n",
       "      <td>0.021854</td>\n",
       "      <td>-0.012438</td>\n",
       "      <td>0.045308</td>\n",
       "      <td>0.043204</td>\n",
       "      <td>0.042259</td>\n",
       "      <td>0.045596</td>\n",
       "      <td>0.038166</td>\n",
       "      <td>-0.009455</td>\n",
       "      <td>-0.007618</td>\n",
       "      <td>0.081651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092262</td>\n",
       "      <td>-0.007678</td>\n",
       "      <td>0.005244</td>\n",
       "      <td>0.089239</td>\n",
       "      <td>-0.139178</td>\n",
       "      <td>-0.021156</td>\n",
       "      <td>-0.021156</td>\n",
       "      <td>0.148996</td>\n",
       "      <td>-0.027790</td>\n",
       "      <td>-0.137405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v178_verified</th>\n",
       "      <td>-0.019354</td>\n",
       "      <td>-0.055177</td>\n",
       "      <td>-0.059419</td>\n",
       "      <td>-0.074205</td>\n",
       "      <td>-0.091117</td>\n",
       "      <td>-0.066806</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>-0.130327</td>\n",
       "      <td>-0.056529</td>\n",
       "      <td>-0.091060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223900</td>\n",
       "      <td>0.315263</td>\n",
       "      <td>0.280222</td>\n",
       "      <td>0.087643</td>\n",
       "      <td>-0.866443</td>\n",
       "      <td>0.038576</td>\n",
       "      <td>0.038576</td>\n",
       "      <td>0.811306</td>\n",
       "      <td>0.088766</td>\n",
       "      <td>-0.879486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v178_nan</th>\n",
       "      <td>0.010840</td>\n",
       "      <td>0.060728</td>\n",
       "      <td>0.039053</td>\n",
       "      <td>0.061561</td>\n",
       "      <td>0.079078</td>\n",
       "      <td>0.052564</td>\n",
       "      <td>-0.010858</td>\n",
       "      <td>0.145945</td>\n",
       "      <td>0.066902</td>\n",
       "      <td>0.060699</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286015</td>\n",
       "      <td>-0.318922</td>\n",
       "      <td>-0.296234</td>\n",
       "      <td>-0.143308</td>\n",
       "      <td>0.987261</td>\n",
       "      <td>-0.059431</td>\n",
       "      <td>-0.059431</td>\n",
       "      <td>-0.922211</td>\n",
       "      <td>-0.078068</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v193_yes</th>\n",
       "      <td>-0.022007</td>\n",
       "      <td>-0.053118</td>\n",
       "      <td>-0.059391</td>\n",
       "      <td>-0.075180</td>\n",
       "      <td>-0.088775</td>\n",
       "      <td>-0.067731</td>\n",
       "      <td>-0.001522</td>\n",
       "      <td>-0.131854</td>\n",
       "      <td>-0.058246</td>\n",
       "      <td>-0.100439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221806</td>\n",
       "      <td>0.313057</td>\n",
       "      <td>0.278148</td>\n",
       "      <td>0.086545</td>\n",
       "      <td>-0.871616</td>\n",
       "      <td>0.067180</td>\n",
       "      <td>0.067180</td>\n",
       "      <td>0.804728</td>\n",
       "      <td>0.088249</td>\n",
       "      <td>-0.884640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v193_nan</th>\n",
       "      <td>0.010840</td>\n",
       "      <td>0.060728</td>\n",
       "      <td>0.039053</td>\n",
       "      <td>0.061561</td>\n",
       "      <td>0.079078</td>\n",
       "      <td>0.052564</td>\n",
       "      <td>-0.010858</td>\n",
       "      <td>0.145945</td>\n",
       "      <td>0.066902</td>\n",
       "      <td>0.060699</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286015</td>\n",
       "      <td>-0.318922</td>\n",
       "      <td>-0.296234</td>\n",
       "      <td>-0.143308</td>\n",
       "      <td>0.987261</td>\n",
       "      <td>-0.059431</td>\n",
       "      <td>-0.059431</td>\n",
       "      <td>-0.922211</td>\n",
       "      <td>-0.078068</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v194_yes</th>\n",
       "      <td>-0.010840</td>\n",
       "      <td>-0.060728</td>\n",
       "      <td>-0.039053</td>\n",
       "      <td>-0.061561</td>\n",
       "      <td>-0.079078</td>\n",
       "      <td>-0.052564</td>\n",
       "      <td>0.010858</td>\n",
       "      <td>-0.145945</td>\n",
       "      <td>-0.066902</td>\n",
       "      <td>-0.060699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286015</td>\n",
       "      <td>0.318922</td>\n",
       "      <td>0.296234</td>\n",
       "      <td>0.143308</td>\n",
       "      <td>-0.987261</td>\n",
       "      <td>0.059431</td>\n",
       "      <td>0.059431</td>\n",
       "      <td>0.922211</td>\n",
       "      <td>0.078068</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v194_nan</th>\n",
       "      <td>0.010840</td>\n",
       "      <td>0.060728</td>\n",
       "      <td>0.039053</td>\n",
       "      <td>0.061561</td>\n",
       "      <td>0.079078</td>\n",
       "      <td>0.052564</td>\n",
       "      <td>-0.010858</td>\n",
       "      <td>0.145945</td>\n",
       "      <td>0.066902</td>\n",
       "      <td>0.060699</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286015</td>\n",
       "      <td>-0.318922</td>\n",
       "      <td>-0.296234</td>\n",
       "      <td>-0.143308</td>\n",
       "      <td>0.987261</td>\n",
       "      <td>-0.059431</td>\n",
       "      <td>-0.059431</td>\n",
       "      <td>-0.922211</td>\n",
       "      <td>-0.078068</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v195_low</th>\n",
       "      <td>0.034318</td>\n",
       "      <td>-0.003731</td>\n",
       "      <td>-0.003506</td>\n",
       "      <td>0.004440</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>0.003290</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>-0.014796</td>\n",
       "      <td>-0.011881</td>\n",
       "      <td>0.229137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037737</td>\n",
       "      <td>-0.002411</td>\n",
       "      <td>0.063331</td>\n",
       "      <td>-0.026424</td>\n",
       "      <td>-0.072091</td>\n",
       "      <td>-0.010958</td>\n",
       "      <td>-0.010958</td>\n",
       "      <td>0.077176</td>\n",
       "      <td>-0.014395</td>\n",
       "      <td>-0.071173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v195_moderate</th>\n",
       "      <td>-0.019232</td>\n",
       "      <td>-0.058975</td>\n",
       "      <td>-0.037650</td>\n",
       "      <td>-0.061829</td>\n",
       "      <td>-0.080104</td>\n",
       "      <td>-0.052669</td>\n",
       "      <td>0.009971</td>\n",
       "      <td>-0.140282</td>\n",
       "      <td>-0.063038</td>\n",
       "      <td>-0.116889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272741</td>\n",
       "      <td>0.315191</td>\n",
       "      <td>0.276453</td>\n",
       "      <td>0.147937</td>\n",
       "      <td>-0.955916</td>\n",
       "      <td>0.061350</td>\n",
       "      <td>0.061350</td>\n",
       "      <td>0.890484</td>\n",
       "      <td>0.080590</td>\n",
       "      <td>-0.968711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v195_nan</th>\n",
       "      <td>0.010840</td>\n",
       "      <td>0.060728</td>\n",
       "      <td>0.039053</td>\n",
       "      <td>0.061561</td>\n",
       "      <td>0.079078</td>\n",
       "      <td>0.052564</td>\n",
       "      <td>-0.010858</td>\n",
       "      <td>0.145945</td>\n",
       "      <td>0.066902</td>\n",
       "      <td>0.060699</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286015</td>\n",
       "      <td>-0.318922</td>\n",
       "      <td>-0.296234</td>\n",
       "      <td>-0.143308</td>\n",
       "      <td>0.987261</td>\n",
       "      <td>-0.059431</td>\n",
       "      <td>-0.059431</td>\n",
       "      <td>-0.922211</td>\n",
       "      <td>-0.078068</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v199_moderate</th>\n",
       "      <td>-0.010840</td>\n",
       "      <td>-0.060728</td>\n",
       "      <td>-0.039053</td>\n",
       "      <td>-0.061561</td>\n",
       "      <td>-0.079078</td>\n",
       "      <td>-0.052564</td>\n",
       "      <td>0.010858</td>\n",
       "      <td>-0.145945</td>\n",
       "      <td>-0.066902</td>\n",
       "      <td>-0.060699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286015</td>\n",
       "      <td>0.318922</td>\n",
       "      <td>0.296234</td>\n",
       "      <td>0.143308</td>\n",
       "      <td>-0.987261</td>\n",
       "      <td>0.059431</td>\n",
       "      <td>0.059431</td>\n",
       "      <td>0.922211</td>\n",
       "      <td>0.078068</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v199_nan</th>\n",
       "      <td>0.010840</td>\n",
       "      <td>0.060728</td>\n",
       "      <td>0.039053</td>\n",
       "      <td>0.061561</td>\n",
       "      <td>0.079078</td>\n",
       "      <td>0.052564</td>\n",
       "      <td>-0.010858</td>\n",
       "      <td>0.145945</td>\n",
       "      <td>0.066902</td>\n",
       "      <td>0.060699</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286015</td>\n",
       "      <td>-0.318922</td>\n",
       "      <td>-0.296234</td>\n",
       "      <td>-0.143308</td>\n",
       "      <td>0.987261</td>\n",
       "      <td>-0.059431</td>\n",
       "      <td>-0.059431</td>\n",
       "      <td>-0.922211</td>\n",
       "      <td>-0.078068</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v201_moderate by proxy reputation and country code</th>\n",
       "      <td>-0.006696</td>\n",
       "      <td>-0.056206</td>\n",
       "      <td>-0.038764</td>\n",
       "      <td>-0.063222</td>\n",
       "      <td>-0.077169</td>\n",
       "      <td>-0.053964</td>\n",
       "      <td>0.010944</td>\n",
       "      <td>-0.144312</td>\n",
       "      <td>-0.065262</td>\n",
       "      <td>-0.059319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288782</td>\n",
       "      <td>0.322007</td>\n",
       "      <td>0.299100</td>\n",
       "      <td>0.144695</td>\n",
       "      <td>-0.996813</td>\n",
       "      <td>0.060006</td>\n",
       "      <td>0.060006</td>\n",
       "      <td>0.912504</td>\n",
       "      <td>0.078824</td>\n",
       "      <td>-0.990417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v201_moderate risk</th>\n",
       "      <td>-0.029653</td>\n",
       "      <td>-0.030867</td>\n",
       "      <td>-0.000895</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>-0.011399</td>\n",
       "      <td>0.011734</td>\n",
       "      <td>-0.000951</td>\n",
       "      <td>-0.007363</td>\n",
       "      <td>-0.009828</td>\n",
       "      <td>-0.008125</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028754</td>\n",
       "      <td>-0.032062</td>\n",
       "      <td>-0.029781</td>\n",
       "      <td>-0.014407</td>\n",
       "      <td>0.099252</td>\n",
       "      <td>-0.005975</td>\n",
       "      <td>-0.005975</td>\n",
       "      <td>0.042078</td>\n",
       "      <td>-0.007848</td>\n",
       "      <td>-0.038805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v201_nan</th>\n",
       "      <td>0.010840</td>\n",
       "      <td>0.060728</td>\n",
       "      <td>0.039053</td>\n",
       "      <td>0.061561</td>\n",
       "      <td>0.079078</td>\n",
       "      <td>0.052564</td>\n",
       "      <td>-0.010858</td>\n",
       "      <td>0.145945</td>\n",
       "      <td>0.066902</td>\n",
       "      <td>0.060699</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286015</td>\n",
       "      <td>-0.318922</td>\n",
       "      <td>-0.296234</td>\n",
       "      <td>-0.143308</td>\n",
       "      <td>0.987261</td>\n",
       "      <td>-0.059431</td>\n",
       "      <td>-0.059431</td>\n",
       "      <td>-0.922211</td>\n",
       "      <td>-0.078068</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v202_good</th>\n",
       "      <td>-0.010840</td>\n",
       "      <td>-0.060728</td>\n",
       "      <td>-0.039053</td>\n",
       "      <td>-0.061561</td>\n",
       "      <td>-0.079078</td>\n",
       "      <td>-0.052564</td>\n",
       "      <td>0.010858</td>\n",
       "      <td>-0.145945</td>\n",
       "      <td>-0.066902</td>\n",
       "      <td>-0.060699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286015</td>\n",
       "      <td>0.318922</td>\n",
       "      <td>0.296234</td>\n",
       "      <td>0.143308</td>\n",
       "      <td>-0.987261</td>\n",
       "      <td>0.059431</td>\n",
       "      <td>0.059431</td>\n",
       "      <td>0.922211</td>\n",
       "      <td>0.078068</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v202_nan</th>\n",
       "      <td>0.010840</td>\n",
       "      <td>0.060728</td>\n",
       "      <td>0.039053</td>\n",
       "      <td>0.061561</td>\n",
       "      <td>0.079078</td>\n",
       "      <td>0.052564</td>\n",
       "      <td>-0.010858</td>\n",
       "      <td>0.145945</td>\n",
       "      <td>0.066902</td>\n",
       "      <td>0.060699</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286015</td>\n",
       "      <td>-0.318922</td>\n",
       "      <td>-0.296234</td>\n",
       "      <td>-0.143308</td>\n",
       "      <td>0.987261</td>\n",
       "      <td>-0.059431</td>\n",
       "      <td>-0.059431</td>\n",
       "      <td>-0.922211</td>\n",
       "      <td>-0.078068</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v203_no</th>\n",
       "      <td>-0.010840</td>\n",
       "      <td>-0.060728</td>\n",
       "      <td>-0.039053</td>\n",
       "      <td>-0.061561</td>\n",
       "      <td>-0.079078</td>\n",
       "      <td>-0.052564</td>\n",
       "      <td>0.010858</td>\n",
       "      <td>-0.145945</td>\n",
       "      <td>-0.066902</td>\n",
       "      <td>-0.060699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286015</td>\n",
       "      <td>0.318922</td>\n",
       "      <td>0.296234</td>\n",
       "      <td>0.143308</td>\n",
       "      <td>-0.987261</td>\n",
       "      <td>0.059431</td>\n",
       "      <td>0.059431</td>\n",
       "      <td>0.922211</td>\n",
       "      <td>0.078068</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v203_nan</th>\n",
       "      <td>0.010840</td>\n",
       "      <td>0.060728</td>\n",
       "      <td>0.039053</td>\n",
       "      <td>0.061561</td>\n",
       "      <td>0.079078</td>\n",
       "      <td>0.052564</td>\n",
       "      <td>-0.010858</td>\n",
       "      <td>0.145945</td>\n",
       "      <td>0.066902</td>\n",
       "      <td>0.060699</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286015</td>\n",
       "      <td>-0.318922</td>\n",
       "      <td>-0.296234</td>\n",
       "      <td>-0.143308</td>\n",
       "      <td>0.987261</td>\n",
       "      <td>-0.059431</td>\n",
       "      <td>-0.059431</td>\n",
       "      <td>-0.922211</td>\n",
       "      <td>-0.078068</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v204_business</th>\n",
       "      <td>0.105443</td>\n",
       "      <td>0.028402</td>\n",
       "      <td>0.018046</td>\n",
       "      <td>-0.015789</td>\n",
       "      <td>0.015715</td>\n",
       "      <td>-0.015172</td>\n",
       "      <td>-0.038260</td>\n",
       "      <td>-0.007491</td>\n",
       "      <td>-0.013774</td>\n",
       "      <td>0.037171</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033224</td>\n",
       "      <td>-0.037046</td>\n",
       "      <td>-0.034411</td>\n",
       "      <td>-0.016647</td>\n",
       "      <td>-0.045416</td>\n",
       "      <td>-0.006903</td>\n",
       "      <td>-0.006903</td>\n",
       "      <td>0.048620</td>\n",
       "      <td>-0.009068</td>\n",
       "      <td>-0.044837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v204_cellular</th>\n",
       "      <td>0.097367</td>\n",
       "      <td>-0.031968</td>\n",
       "      <td>-0.139309</td>\n",
       "      <td>-0.051358</td>\n",
       "      <td>-0.044091</td>\n",
       "      <td>-0.052360</td>\n",
       "      <td>-0.120952</td>\n",
       "      <td>-0.033863</td>\n",
       "      <td>-0.031032</td>\n",
       "      <td>-0.070660</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.144226</td>\n",
       "      <td>-0.160820</td>\n",
       "      <td>-0.149379</td>\n",
       "      <td>-0.072265</td>\n",
       "      <td>-0.197154</td>\n",
       "      <td>0.065831</td>\n",
       "      <td>0.065831</td>\n",
       "      <td>0.152270</td>\n",
       "      <td>0.034042</td>\n",
       "      <td>-0.194643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v204_college</th>\n",
       "      <td>-0.017098</td>\n",
       "      <td>0.010337</td>\n",
       "      <td>0.093237</td>\n",
       "      <td>-0.019185</td>\n",
       "      <td>-0.018105</td>\n",
       "      <td>-0.020001</td>\n",
       "      <td>-0.027601</td>\n",
       "      <td>-0.014393</td>\n",
       "      <td>-0.005667</td>\n",
       "      <td>0.003519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016579</td>\n",
       "      <td>-0.018487</td>\n",
       "      <td>-0.017172</td>\n",
       "      <td>-0.008307</td>\n",
       "      <td>-0.022664</td>\n",
       "      <td>-0.003445</td>\n",
       "      <td>-0.003445</td>\n",
       "      <td>0.024262</td>\n",
       "      <td>-0.004525</td>\n",
       "      <td>-0.022375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v204_dialup</th>\n",
       "      <td>-0.017098</td>\n",
       "      <td>-0.005009</td>\n",
       "      <td>-0.015165</td>\n",
       "      <td>0.020140</td>\n",
       "      <td>0.016491</td>\n",
       "      <td>0.021903</td>\n",
       "      <td>-0.022365</td>\n",
       "      <td>-0.014393</td>\n",
       "      <td>-0.005667</td>\n",
       "      <td>0.055606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016579</td>\n",
       "      <td>-0.018487</td>\n",
       "      <td>-0.017172</td>\n",
       "      <td>-0.008307</td>\n",
       "      <td>-0.022664</td>\n",
       "      <td>-0.003445</td>\n",
       "      <td>-0.003445</td>\n",
       "      <td>0.024262</td>\n",
       "      <td>-0.004525</td>\n",
       "      <td>-0.022375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v204_mobile</th>\n",
       "      <td>-0.024923</td>\n",
       "      <td>0.021698</td>\n",
       "      <td>-0.010204</td>\n",
       "      <td>0.016620</td>\n",
       "      <td>0.017533</td>\n",
       "      <td>0.019737</td>\n",
       "      <td>0.033399</td>\n",
       "      <td>-0.030635</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>0.017673</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.236314</td>\n",
       "      <td>-0.219503</td>\n",
       "      <td>-0.106188</td>\n",
       "      <td>-0.289705</td>\n",
       "      <td>-0.008062</td>\n",
       "      <td>-0.008062</td>\n",
       "      <td>0.280704</td>\n",
       "      <td>-0.002714</td>\n",
       "      <td>-0.286015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v204_residential</th>\n",
       "      <td>0.077241</td>\n",
       "      <td>0.017588</td>\n",
       "      <td>-0.090875</td>\n",
       "      <td>-0.061750</td>\n",
       "      <td>-0.120228</td>\n",
       "      <td>-0.059451</td>\n",
       "      <td>-0.048993</td>\n",
       "      <td>-0.050454</td>\n",
       "      <td>-0.049136</td>\n",
       "      <td>-0.099213</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.236314</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.244757</td>\n",
       "      <td>-0.118406</td>\n",
       "      <td>-0.323037</td>\n",
       "      <td>-0.015467</td>\n",
       "      <td>0.051805</td>\n",
       "      <td>0.290778</td>\n",
       "      <td>0.038595</td>\n",
       "      <td>-0.318922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v204_wifi</th>\n",
       "      <td>-0.148913</td>\n",
       "      <td>-0.037195</td>\n",
       "      <td>0.104379</td>\n",
       "      <td>0.043348</td>\n",
       "      <td>0.070998</td>\n",
       "      <td>0.048794</td>\n",
       "      <td>0.101896</td>\n",
       "      <td>-0.033850</td>\n",
       "      <td>0.017068</td>\n",
       "      <td>0.031243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219503</td>\n",
       "      <td>-0.244757</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.109982</td>\n",
       "      <td>-0.300056</td>\n",
       "      <td>0.059917</td>\n",
       "      <td>-0.045610</td>\n",
       "      <td>0.270852</td>\n",
       "      <td>0.047903</td>\n",
       "      <td>-0.296234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v204_wired</th>\n",
       "      <td>-0.002650</td>\n",
       "      <td>-0.082489</td>\n",
       "      <td>0.067423</td>\n",
       "      <td>-0.044838</td>\n",
       "      <td>-0.036415</td>\n",
       "      <td>-0.043985</td>\n",
       "      <td>0.056682</td>\n",
       "      <td>-0.037192</td>\n",
       "      <td>-0.029950</td>\n",
       "      <td>0.045614</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106188</td>\n",
       "      <td>-0.118406</td>\n",
       "      <td>-0.109982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.145158</td>\n",
       "      <td>-0.022065</td>\n",
       "      <td>0.040331</td>\n",
       "      <td>0.142633</td>\n",
       "      <td>-0.028984</td>\n",
       "      <td>-0.143308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v204_nan</th>\n",
       "      <td>0.005322</td>\n",
       "      <td>0.053279</td>\n",
       "      <td>0.046851</td>\n",
       "      <td>0.061015</td>\n",
       "      <td>0.075617</td>\n",
       "      <td>0.051670</td>\n",
       "      <td>-0.012713</td>\n",
       "      <td>0.143450</td>\n",
       "      <td>0.063949</td>\n",
       "      <td>0.059518</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.289705</td>\n",
       "      <td>-0.323037</td>\n",
       "      <td>-0.300056</td>\n",
       "      <td>-0.145158</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.060197</td>\n",
       "      <td>-0.060197</td>\n",
       "      <td>-0.909306</td>\n",
       "      <td>-0.079076</td>\n",
       "      <td>0.987261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172.1_n</th>\n",
       "      <td>-0.045414</td>\n",
       "      <td>0.018721</td>\n",
       "      <td>-0.035833</td>\n",
       "      <td>-0.023792</td>\n",
       "      <td>-0.008706</td>\n",
       "      <td>-0.023801</td>\n",
       "      <td>-0.013708</td>\n",
       "      <td>-0.024368</td>\n",
       "      <td>-0.018716</td>\n",
       "      <td>-0.074746</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008062</td>\n",
       "      <td>-0.015467</td>\n",
       "      <td>0.059917</td>\n",
       "      <td>-0.022065</td>\n",
       "      <td>-0.060197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.009150</td>\n",
       "      <td>-0.141990</td>\n",
       "      <td>-0.012020</td>\n",
       "      <td>-0.059431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172.1_p</th>\n",
       "      <td>-0.010143</td>\n",
       "      <td>0.039101</td>\n",
       "      <td>-0.040280</td>\n",
       "      <td>-0.031783</td>\n",
       "      <td>-0.048088</td>\n",
       "      <td>-0.032463</td>\n",
       "      <td>-0.061391</td>\n",
       "      <td>-0.015127</td>\n",
       "      <td>-0.016883</td>\n",
       "      <td>-0.059899</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008062</td>\n",
       "      <td>0.051805</td>\n",
       "      <td>-0.045610</td>\n",
       "      <td>0.040331</td>\n",
       "      <td>-0.060197</td>\n",
       "      <td>-0.009150</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.141990</td>\n",
       "      <td>-0.012020</td>\n",
       "      <td>-0.059431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172.1_u</th>\n",
       "      <td>0.009589</td>\n",
       "      <td>-0.055188</td>\n",
       "      <td>-0.022865</td>\n",
       "      <td>-0.048033</td>\n",
       "      <td>-0.061443</td>\n",
       "      <td>-0.039713</td>\n",
       "      <td>0.019671</td>\n",
       "      <td>-0.134820</td>\n",
       "      <td>-0.055532</td>\n",
       "      <td>-0.015655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280704</td>\n",
       "      <td>0.290778</td>\n",
       "      <td>0.270852</td>\n",
       "      <td>0.142633</td>\n",
       "      <td>-0.909306</td>\n",
       "      <td>-0.141990</td>\n",
       "      <td>-0.141990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.186519</td>\n",
       "      <td>-0.922211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172.1_y</th>\n",
       "      <td>-0.032629</td>\n",
       "      <td>-0.057636</td>\n",
       "      <td>0.002458</td>\n",
       "      <td>-0.000563</td>\n",
       "      <td>-0.012874</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.023207</td>\n",
       "      <td>0.006430</td>\n",
       "      <td>-0.007136</td>\n",
       "      <td>-0.058134</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002714</td>\n",
       "      <td>0.038595</td>\n",
       "      <td>0.047903</td>\n",
       "      <td>-0.028984</td>\n",
       "      <td>-0.079076</td>\n",
       "      <td>-0.012020</td>\n",
       "      <td>-0.012020</td>\n",
       "      <td>-0.186519</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.078068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172.1_nan</th>\n",
       "      <td>0.010840</td>\n",
       "      <td>0.060728</td>\n",
       "      <td>0.039053</td>\n",
       "      <td>0.061561</td>\n",
       "      <td>0.079078</td>\n",
       "      <td>0.052564</td>\n",
       "      <td>-0.010858</td>\n",
       "      <td>0.145945</td>\n",
       "      <td>0.066902</td>\n",
       "      <td>0.060699</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286015</td>\n",
       "      <td>-0.318922</td>\n",
       "      <td>-0.296234</td>\n",
       "      <td>-0.143308</td>\n",
       "      <td>0.987261</td>\n",
       "      <td>-0.059431</td>\n",
       "      <td>-0.059431</td>\n",
       "      <td>-0.922211</td>\n",
       "      <td>-0.078068</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    response      v001  \\\n",
       "response                                            1.000000  0.016594   \n",
       "v001                                                0.016594  1.000000   \n",
       "v002                                               -0.072353 -0.028172   \n",
       "v4                                                 -0.007668  0.026159   \n",
       "v5                                                 -0.013845  0.042749   \n",
       "v14                                                -0.017492  0.026423   \n",
       "v29                                                -0.172579 -0.042262   \n",
       "v120                                                0.051613  0.062640   \n",
       "v123                                                0.001951  0.065808   \n",
       "v173                                                0.042317 -0.023079   \n",
       "v174                                               -0.044762  0.023308   \n",
       "v175                                                0.016363  0.001833   \n",
       "v176                                               -0.019849 -0.002542   \n",
       "v177                                                0.048428 -0.002857   \n",
       "v180                                                0.022540  0.034855   \n",
       "v181                                                0.026332 -0.013670   \n",
       "v182                                                0.066963  0.027891   \n",
       "v183                                                0.021228  0.031512   \n",
       "v185                                                0.018609  0.032782   \n",
       "v191                                                0.194025 -0.026984   \n",
       "v192                                                0.194025 -0.026984   \n",
       "v196                                                0.034318 -0.003731   \n",
       "v197                                                0.034318 -0.003731   \n",
       "v198                                                     NaN       NaN   \n",
       "v200                                                0.029653  0.030867   \n",
       "v178_certified                                     -0.024196  0.020057   \n",
       "v178_emailinexistent                                0.012306  0.005338   \n",
       "v178_validdomain                                    0.021854 -0.012438   \n",
       "v178_verified                                      -0.019354 -0.055177   \n",
       "v178_nan                                            0.010840  0.060728   \n",
       "...                                                      ...       ...   \n",
       "v193_yes                                           -0.022007 -0.053118   \n",
       "v193_nan                                            0.010840  0.060728   \n",
       "v194_yes                                           -0.010840 -0.060728   \n",
       "v194_nan                                            0.010840  0.060728   \n",
       "v195_low                                            0.034318 -0.003731   \n",
       "v195_moderate                                      -0.019232 -0.058975   \n",
       "v195_nan                                            0.010840  0.060728   \n",
       "v199_moderate                                      -0.010840 -0.060728   \n",
       "v199_nan                                            0.010840  0.060728   \n",
       "v201_moderate by proxy reputation and country code -0.006696 -0.056206   \n",
       "v201_moderate risk                                 -0.029653 -0.030867   \n",
       "v201_nan                                            0.010840  0.060728   \n",
       "v202_good                                          -0.010840 -0.060728   \n",
       "v202_nan                                            0.010840  0.060728   \n",
       "v203_no                                            -0.010840 -0.060728   \n",
       "v203_nan                                            0.010840  0.060728   \n",
       "v204_business                                       0.105443  0.028402   \n",
       "v204_cellular                                       0.097367 -0.031968   \n",
       "v204_college                                       -0.017098  0.010337   \n",
       "v204_dialup                                        -0.017098 -0.005009   \n",
       "v204_mobile                                        -0.024923  0.021698   \n",
       "v204_residential                                    0.077241  0.017588   \n",
       "v204_wifi                                          -0.148913 -0.037195   \n",
       "v204_wired                                         -0.002650 -0.082489   \n",
       "v204_nan                                            0.005322  0.053279   \n",
       "v172.1_n                                           -0.045414  0.018721   \n",
       "v172.1_p                                           -0.010143  0.039101   \n",
       "v172.1_u                                            0.009589 -0.055188   \n",
       "v172.1_y                                           -0.032629 -0.057636   \n",
       "v172.1_nan                                          0.010840  0.060728   \n",
       "\n",
       "                                                        v002        v4  \\\n",
       "response                                           -0.072353 -0.007668   \n",
       "v001                                               -0.028172  0.026159   \n",
       "v002                                                1.000000  0.161154   \n",
       "v4                                                  0.161154  1.000000   \n",
       "v5                                                  0.089772  0.738650   \n",
       "v14                                                 0.156599  0.985423   \n",
       "v29                                                 0.150948  0.302075   \n",
       "v120                                               -0.019944  0.209135   \n",
       "v123                                                0.015985  0.277026   \n",
       "v173                                                0.056365  0.010641   \n",
       "v174                                               -0.054430 -0.009915   \n",
       "v175                                                0.036745  0.022826   \n",
       "v176                                               -0.034321 -0.022698   \n",
       "v177                                               -0.021130  0.009787   \n",
       "v180                                                0.036069  0.018493   \n",
       "v181                                                0.046281  0.040124   \n",
       "v182                                                0.049610 -0.013755   \n",
       "v183                                                0.023708 -0.007962   \n",
       "v185                                                0.030687  0.016085   \n",
       "v191                                               -0.011798 -0.017876   \n",
       "v192                                               -0.011798 -0.017876   \n",
       "v196                                               -0.003506  0.004440   \n",
       "v197                                               -0.003506  0.004440   \n",
       "v198                                                     NaN       NaN   \n",
       "v200                                                0.000895 -0.013900   \n",
       "v178_certified                                      0.001343 -0.007672   \n",
       "v178_emailinexistent                                0.012175 -0.018744   \n",
       "v178_validdomain                                    0.045308  0.043204   \n",
       "v178_verified                                      -0.059419 -0.074205   \n",
       "v178_nan                                            0.039053  0.061561   \n",
       "...                                                      ...       ...   \n",
       "v193_yes                                           -0.059391 -0.075180   \n",
       "v193_nan                                            0.039053  0.061561   \n",
       "v194_yes                                           -0.039053 -0.061561   \n",
       "v194_nan                                            0.039053  0.061561   \n",
       "v195_low                                           -0.003506  0.004440   \n",
       "v195_moderate                                      -0.037650 -0.061829   \n",
       "v195_nan                                            0.039053  0.061561   \n",
       "v199_moderate                                      -0.039053 -0.061561   \n",
       "v199_nan                                            0.039053  0.061561   \n",
       "v201_moderate by proxy reputation and country code -0.038764 -0.063222   \n",
       "v201_moderate risk                                 -0.000895  0.013900   \n",
       "v201_nan                                            0.039053  0.061561   \n",
       "v202_good                                          -0.039053 -0.061561   \n",
       "v202_nan                                            0.039053  0.061561   \n",
       "v203_no                                            -0.039053 -0.061561   \n",
       "v203_nan                                            0.039053  0.061561   \n",
       "v204_business                                       0.018046 -0.015789   \n",
       "v204_cellular                                      -0.139309 -0.051358   \n",
       "v204_college                                        0.093237 -0.019185   \n",
       "v204_dialup                                        -0.015165  0.020140   \n",
       "v204_mobile                                        -0.010204  0.016620   \n",
       "v204_residential                                   -0.090875 -0.061750   \n",
       "v204_wifi                                           0.104379  0.043348   \n",
       "v204_wired                                          0.067423 -0.044838   \n",
       "v204_nan                                            0.046851  0.061015   \n",
       "v172.1_n                                           -0.035833 -0.023792   \n",
       "v172.1_p                                           -0.040280 -0.031783   \n",
       "v172.1_u                                           -0.022865 -0.048033   \n",
       "v172.1_y                                            0.002458 -0.000563   \n",
       "v172.1_nan                                          0.039053  0.061561   \n",
       "\n",
       "                                                          v5       v14  \\\n",
       "response                                           -0.013845 -0.017492   \n",
       "v001                                                0.042749  0.026423   \n",
       "v002                                                0.089772  0.156599   \n",
       "v4                                                  0.738650  0.985423   \n",
       "v5                                                  1.000000  0.739335   \n",
       "v14                                                 0.739335  1.000000   \n",
       "v29                                                 0.312050  0.303795   \n",
       "v120                                                0.329635  0.225246   \n",
       "v123                                                0.383194  0.289810   \n",
       "v173                                                0.022785  0.016430   \n",
       "v174                                               -0.020723 -0.015724   \n",
       "v175                                                0.022109  0.020325   \n",
       "v176                                               -0.020502 -0.020099   \n",
       "v177                                                0.030602  0.006996   \n",
       "v180                                                0.031174  0.016046   \n",
       "v181                                                0.032608  0.042488   \n",
       "v182                                                0.037750 -0.017427   \n",
       "v183                                               -0.008904 -0.009189   \n",
       "v185                                                0.026678  0.013559   \n",
       "v191                                               -0.017656 -0.013643   \n",
       "v192                                               -0.017656 -0.013643   \n",
       "v196                                                0.008439  0.003290   \n",
       "v197                                                0.008439  0.003290   \n",
       "v198                                                     NaN       NaN   \n",
       "v200                                                0.011399 -0.011734   \n",
       "v178_certified                                      0.023338 -0.007340   \n",
       "v178_emailinexistent                               -0.036280 -0.018398   \n",
       "v178_validdomain                                    0.042259  0.045596   \n",
       "v178_verified                                      -0.091117 -0.066806   \n",
       "v178_nan                                            0.079078  0.052564   \n",
       "...                                                      ...       ...   \n",
       "v193_yes                                           -0.088775 -0.067731   \n",
       "v193_nan                                            0.079078  0.052564   \n",
       "v194_yes                                           -0.079078 -0.052564   \n",
       "v194_nan                                            0.079078  0.052564   \n",
       "v195_low                                            0.008439  0.003290   \n",
       "v195_moderate                                      -0.080104 -0.052669   \n",
       "v195_nan                                            0.079078  0.052564   \n",
       "v199_moderate                                      -0.079078 -0.052564   \n",
       "v199_nan                                            0.079078  0.052564   \n",
       "v201_moderate by proxy reputation and country code -0.077169 -0.053964   \n",
       "v201_moderate risk                                 -0.011399  0.011734   \n",
       "v201_nan                                            0.079078  0.052564   \n",
       "v202_good                                          -0.079078 -0.052564   \n",
       "v202_nan                                            0.079078  0.052564   \n",
       "v203_no                                            -0.079078 -0.052564   \n",
       "v203_nan                                            0.079078  0.052564   \n",
       "v204_business                                       0.015715 -0.015172   \n",
       "v204_cellular                                      -0.044091 -0.052360   \n",
       "v204_college                                       -0.018105 -0.020001   \n",
       "v204_dialup                                         0.016491  0.021903   \n",
       "v204_mobile                                         0.017533  0.019737   \n",
       "v204_residential                                   -0.120228 -0.059451   \n",
       "v204_wifi                                           0.070998  0.048794   \n",
       "v204_wired                                         -0.036415 -0.043985   \n",
       "v204_nan                                            0.075617  0.051670   \n",
       "v172.1_n                                           -0.008706 -0.023801   \n",
       "v172.1_p                                           -0.048088 -0.032463   \n",
       "v172.1_u                                           -0.061443 -0.039713   \n",
       "v172.1_y                                           -0.012874  0.001402   \n",
       "v172.1_nan                                          0.079078  0.052564   \n",
       "\n",
       "                                                         v29      v120  \\\n",
       "response                                           -0.172579  0.051613   \n",
       "v001                                               -0.042262  0.062640   \n",
       "v002                                                0.150948 -0.019944   \n",
       "v4                                                  0.302075  0.209135   \n",
       "v5                                                  0.312050  0.329635   \n",
       "v14                                                 0.303795  0.225246   \n",
       "v29                                                 1.000000  0.157450   \n",
       "v120                                                0.157450  1.000000   \n",
       "v123                                                0.163382  0.733878   \n",
       "v173                                                0.058766  0.017526   \n",
       "v174                                               -0.056870 -0.016925   \n",
       "v175                                               -0.002560  0.011377   \n",
       "v176                                                0.005673 -0.012557   \n",
       "v177                                               -0.045187  0.001383   \n",
       "v180                                               -0.021656  0.013454   \n",
       "v181                                                0.034544 -0.011165   \n",
       "v182                                                0.010566  0.037434   \n",
       "v183                                               -0.039029 -0.008797   \n",
       "v185                                               -0.022860  0.010256   \n",
       "v191                                               -0.074641 -0.006081   \n",
       "v192                                               -0.074641 -0.006081   \n",
       "v196                                                0.002975 -0.014796   \n",
       "v197                                                0.002975 -0.014796   \n",
       "v198                                                     NaN       NaN   \n",
       "v200                                                0.000951  0.007363   \n",
       "v178_certified                                     -0.024240 -0.011752   \n",
       "v178_emailinexistent                               -0.034325 -0.019692   \n",
       "v178_validdomain                                    0.038166 -0.009455   \n",
       "v178_verified                                       0.001096 -0.130327   \n",
       "v178_nan                                           -0.010858  0.145945   \n",
       "...                                                      ...       ...   \n",
       "v193_yes                                           -0.001522 -0.131854   \n",
       "v193_nan                                           -0.010858  0.145945   \n",
       "v194_yes                                            0.010858 -0.145945   \n",
       "v194_nan                                           -0.010858  0.145945   \n",
       "v195_low                                            0.002975 -0.014796   \n",
       "v195_moderate                                       0.009971 -0.140282   \n",
       "v195_nan                                           -0.010858  0.145945   \n",
       "v199_moderate                                       0.010858 -0.145945   \n",
       "v199_nan                                           -0.010858  0.145945   \n",
       "v201_moderate by proxy reputation and country code  0.010944 -0.144312   \n",
       "v201_moderate risk                                 -0.000951 -0.007363   \n",
       "v201_nan                                           -0.010858  0.145945   \n",
       "v202_good                                           0.010858 -0.145945   \n",
       "v202_nan                                           -0.010858  0.145945   \n",
       "v203_no                                             0.010858 -0.145945   \n",
       "v203_nan                                           -0.010858  0.145945   \n",
       "v204_business                                      -0.038260 -0.007491   \n",
       "v204_cellular                                      -0.120952 -0.033863   \n",
       "v204_college                                       -0.027601 -0.014393   \n",
       "v204_dialup                                        -0.022365 -0.014393   \n",
       "v204_mobile                                         0.033399 -0.030635   \n",
       "v204_residential                                   -0.048993 -0.050454   \n",
       "v204_wifi                                           0.101896 -0.033850   \n",
       "v204_wired                                          0.056682 -0.037192   \n",
       "v204_nan                                           -0.012713  0.143450   \n",
       "v172.1_n                                           -0.013708 -0.024368   \n",
       "v172.1_p                                           -0.061391 -0.015127   \n",
       "v172.1_u                                            0.019671 -0.134820   \n",
       "v172.1_y                                            0.023207  0.006430   \n",
       "v172.1_nan                                         -0.010858  0.145945   \n",
       "\n",
       "                                                        v123      v173  \\\n",
       "response                                            0.001951  0.042317   \n",
       "v001                                                0.065808 -0.023079   \n",
       "v002                                                0.015985  0.056365   \n",
       "v4                                                  0.277026  0.010641   \n",
       "v5                                                  0.383194  0.022785   \n",
       "v14                                                 0.289810  0.016430   \n",
       "v29                                                 0.163382  0.058766   \n",
       "v120                                                0.733878  0.017526   \n",
       "v123                                                1.000000  0.051716   \n",
       "v173                                                0.051716  1.000000   \n",
       "v174                                               -0.050899 -0.999832   \n",
       "v175                                                0.010423  0.096303   \n",
       "v176                                               -0.010168 -0.094509   \n",
       "v177                                               -0.001916 -0.069621   \n",
       "v180                                               -0.003963  0.065332   \n",
       "v181                                               -0.008010  0.096625   \n",
       "v182                                                0.028961  0.514751   \n",
       "v183                                               -0.017028  0.052509   \n",
       "v185                                               -0.006240  0.057240   \n",
       "v191                                                0.005703 -0.004563   \n",
       "v192                                                0.005703 -0.004563   \n",
       "v196                                               -0.011881  0.229137   \n",
       "v197                                               -0.011881  0.229137   \n",
       "v198                                                     NaN       NaN   \n",
       "v200                                                0.009828  0.008125   \n",
       "v178_certified                                     -0.014852 -0.085115   \n",
       "v178_emailinexistent                               -0.013774  0.039195   \n",
       "v178_validdomain                                   -0.007618  0.081651   \n",
       "v178_verified                                      -0.056529 -0.091060   \n",
       "v178_nan                                            0.066902  0.060699   \n",
       "...                                                      ...       ...   \n",
       "v193_yes                                           -0.058246 -0.100439   \n",
       "v193_nan                                            0.066902  0.060699   \n",
       "v194_yes                                           -0.066902 -0.060699   \n",
       "v194_nan                                            0.066902  0.060699   \n",
       "v195_low                                           -0.011881  0.229137   \n",
       "v195_moderate                                      -0.063038 -0.116889   \n",
       "v195_nan                                            0.066902  0.060699   \n",
       "v199_moderate                                      -0.066902 -0.060699   \n",
       "v199_nan                                            0.066902  0.060699   \n",
       "v201_moderate by proxy reputation and country code -0.065262 -0.059319   \n",
       "v201_moderate risk                                 -0.009828 -0.008125   \n",
       "v201_nan                                            0.066902  0.060699   \n",
       "v202_good                                          -0.066902 -0.060699   \n",
       "v202_nan                                            0.066902  0.060699   \n",
       "v203_no                                            -0.066902 -0.060699   \n",
       "v203_nan                                            0.066902  0.060699   \n",
       "v204_business                                      -0.013774  0.037171   \n",
       "v204_cellular                                      -0.031032 -0.070660   \n",
       "v204_college                                       -0.005667  0.003519   \n",
       "v204_dialup                                        -0.005667  0.055606   \n",
       "v204_mobile                                         0.003460  0.017673   \n",
       "v204_residential                                   -0.049136 -0.099213   \n",
       "v204_wifi                                           0.017068  0.031243   \n",
       "v204_wired                                         -0.029950  0.045614   \n",
       "v204_nan                                            0.063949  0.059518   \n",
       "v172.1_n                                           -0.018716 -0.074746   \n",
       "v172.1_p                                           -0.016883 -0.059899   \n",
       "v172.1_u                                           -0.055532 -0.015655   \n",
       "v172.1_y                                           -0.007136 -0.058134   \n",
       "v172.1_nan                                          0.066902  0.060699   \n",
       "\n",
       "                                                       ...      v204_mobile  \\\n",
       "response                                               ...        -0.024923   \n",
       "v001                                                   ...         0.021698   \n",
       "v002                                                   ...        -0.010204   \n",
       "v4                                                     ...         0.016620   \n",
       "v5                                                     ...         0.017533   \n",
       "v14                                                    ...         0.019737   \n",
       "v29                                                    ...         0.033399   \n",
       "v120                                                   ...        -0.030635   \n",
       "v123                                                   ...         0.003460   \n",
       "v173                                                   ...         0.017673   \n",
       "v174                                                   ...        -0.011385   \n",
       "v175                                                   ...         0.009334   \n",
       "v176                                                   ...         0.004150   \n",
       "v177                                                   ...        -0.040159   \n",
       "v180                                                   ...        -0.023473   \n",
       "v181                                                   ...         0.103508   \n",
       "v182                                                   ...        -0.117849   \n",
       "v183                                                   ...         0.023692   \n",
       "v185                                                   ...        -0.023946   \n",
       "v191                                                   ...         0.001890   \n",
       "v192                                                   ...         0.001890   \n",
       "v196                                                   ...         0.037737   \n",
       "v197                                                   ...         0.037737   \n",
       "v198                                                   ...              NaN   \n",
       "v200                                                   ...         0.028754   \n",
       "v178_certified                                         ...        -0.023462   \n",
       "v178_emailinexistent                                   ...         0.061771   \n",
       "v178_validdomain                                       ...         0.092262   \n",
       "v178_verified                                          ...         0.223900   \n",
       "v178_nan                                               ...        -0.286015   \n",
       "...                                                    ...              ...   \n",
       "v193_yes                                               ...         0.221806   \n",
       "v193_nan                                               ...        -0.286015   \n",
       "v194_yes                                               ...         0.286015   \n",
       "v194_nan                                               ...        -0.286015   \n",
       "v195_low                                               ...         0.037737   \n",
       "v195_moderate                                          ...         0.272741   \n",
       "v195_nan                                               ...        -0.286015   \n",
       "v199_moderate                                          ...         0.286015   \n",
       "v199_nan                                               ...        -0.286015   \n",
       "v201_moderate by proxy reputation and country code     ...         0.288782   \n",
       "v201_moderate risk                                     ...        -0.028754   \n",
       "v201_nan                                               ...        -0.286015   \n",
       "v202_good                                              ...         0.286015   \n",
       "v202_nan                                               ...        -0.286015   \n",
       "v203_no                                                ...         0.286015   \n",
       "v203_nan                                               ...        -0.286015   \n",
       "v204_business                                          ...        -0.033224   \n",
       "v204_cellular                                          ...        -0.144226   \n",
       "v204_college                                           ...        -0.016579   \n",
       "v204_dialup                                            ...        -0.016579   \n",
       "v204_mobile                                            ...         1.000000   \n",
       "v204_residential                                       ...        -0.236314   \n",
       "v204_wifi                                              ...        -0.219503   \n",
       "v204_wired                                             ...        -0.106188   \n",
       "v204_nan                                               ...        -0.289705   \n",
       "v172.1_n                                               ...        -0.008062   \n",
       "v172.1_p                                               ...        -0.008062   \n",
       "v172.1_u                                               ...         0.280704   \n",
       "v172.1_y                                               ...        -0.002714   \n",
       "v172.1_nan                                             ...        -0.286015   \n",
       "\n",
       "                                                    v204_residential  \\\n",
       "response                                                    0.077241   \n",
       "v001                                                        0.017588   \n",
       "v002                                                       -0.090875   \n",
       "v4                                                         -0.061750   \n",
       "v5                                                         -0.120228   \n",
       "v14                                                        -0.059451   \n",
       "v29                                                        -0.048993   \n",
       "v120                                                       -0.050454   \n",
       "v123                                                       -0.049136   \n",
       "v173                                                       -0.099213   \n",
       "v174                                                        0.086854   \n",
       "v175                                                       -0.098594   \n",
       "v176                                                        0.084703   \n",
       "v177                                                       -0.023157   \n",
       "v180                                                       -0.132832   \n",
       "v181                                                       -0.010617   \n",
       "v182                                                       -0.152248   \n",
       "v183                                                       -0.101339   \n",
       "v185                                                       -0.124233   \n",
       "v191                                                        0.070954   \n",
       "v192                                                        0.070954   \n",
       "v196                                                       -0.002411   \n",
       "v197                                                       -0.002411   \n",
       "v198                                                             NaN   \n",
       "v200                                                        0.032062   \n",
       "v178_certified                                             -0.026161   \n",
       "v178_emailinexistent                                       -0.037046   \n",
       "v178_validdomain                                           -0.007678   \n",
       "v178_verified                                               0.315263   \n",
       "v178_nan                                                   -0.318922   \n",
       "...                                                              ...   \n",
       "v193_yes                                                    0.313057   \n",
       "v193_nan                                                   -0.318922   \n",
       "v194_yes                                                    0.318922   \n",
       "v194_nan                                                   -0.318922   \n",
       "v195_low                                                   -0.002411   \n",
       "v195_moderate                                               0.315191   \n",
       "v195_nan                                                   -0.318922   \n",
       "v199_moderate                                               0.318922   \n",
       "v199_nan                                                   -0.318922   \n",
       "v201_moderate by proxy reputation and country code          0.322007   \n",
       "v201_moderate risk                                         -0.032062   \n",
       "v201_nan                                                   -0.318922   \n",
       "v202_good                                                   0.318922   \n",
       "v202_nan                                                   -0.318922   \n",
       "v203_no                                                     0.318922   \n",
       "v203_nan                                                   -0.318922   \n",
       "v204_business                                              -0.037046   \n",
       "v204_cellular                                              -0.160820   \n",
       "v204_college                                               -0.018487   \n",
       "v204_dialup                                                -0.018487   \n",
       "v204_mobile                                                -0.236314   \n",
       "v204_residential                                            1.000000   \n",
       "v204_wifi                                                  -0.244757   \n",
       "v204_wired                                                 -0.118406   \n",
       "v204_nan                                                   -0.323037   \n",
       "v172.1_n                                                   -0.015467   \n",
       "v172.1_p                                                    0.051805   \n",
       "v172.1_u                                                    0.290778   \n",
       "v172.1_y                                                    0.038595   \n",
       "v172.1_nan                                                 -0.318922   \n",
       "\n",
       "                                                    v204_wifi  v204_wired  \\\n",
       "response                                            -0.148913   -0.002650   \n",
       "v001                                                -0.037195   -0.082489   \n",
       "v002                                                 0.104379    0.067423   \n",
       "v4                                                   0.043348   -0.044838   \n",
       "v5                                                   0.070998   -0.036415   \n",
       "v14                                                  0.048794   -0.043985   \n",
       "v29                                                  0.101896    0.056682   \n",
       "v120                                                -0.033850   -0.037192   \n",
       "v123                                                 0.017068   -0.029950   \n",
       "v173                                                 0.031243    0.045614   \n",
       "v174                                                -0.025317   -0.042905   \n",
       "v175                                                -0.037143   -0.022360   \n",
       "v176                                                 0.050265    0.028594   \n",
       "v177                                                -0.060555   -0.029300   \n",
       "v180                                                -0.054981   -0.029743   \n",
       "v181                                                 0.010018    0.099824   \n",
       "v182                                                -0.138372   -0.071711   \n",
       "v183                                                -0.016571    0.034264   \n",
       "v185                                                -0.055139   -0.017898   \n",
       "v191                                                 0.032342    0.018522   \n",
       "v192                                                 0.032342    0.018522   \n",
       "v196                                                 0.063331   -0.026424   \n",
       "v197                                                 0.063331   -0.026424   \n",
       "v198                                                      NaN         NaN   \n",
       "v200                                                 0.029781    0.014407   \n",
       "v178_certified                                      -0.024300   -0.011756   \n",
       "v178_emailinexistent                                 0.012032    0.065733   \n",
       "v178_validdomain                                     0.005244    0.089239   \n",
       "v178_verified                                        0.280222    0.087643   \n",
       "v178_nan                                            -0.296234   -0.143308   \n",
       "...                                                       ...         ...   \n",
       "v193_yes                                             0.278148    0.086545   \n",
       "v193_nan                                            -0.296234   -0.143308   \n",
       "v194_yes                                             0.296234    0.143308   \n",
       "v194_nan                                            -0.296234   -0.143308   \n",
       "v195_low                                             0.063331   -0.026424   \n",
       "v195_moderate                                        0.276453    0.147937   \n",
       "v195_nan                                            -0.296234   -0.143308   \n",
       "v199_moderate                                        0.296234    0.143308   \n",
       "v199_nan                                            -0.296234   -0.143308   \n",
       "v201_moderate by proxy reputation and country code   0.299100    0.144695   \n",
       "v201_moderate risk                                  -0.029781   -0.014407   \n",
       "v201_nan                                            -0.296234   -0.143308   \n",
       "v202_good                                            0.296234    0.143308   \n",
       "v202_nan                                            -0.296234   -0.143308   \n",
       "v203_no                                              0.296234    0.143308   \n",
       "v203_nan                                            -0.296234   -0.143308   \n",
       "v204_business                                       -0.034411   -0.016647   \n",
       "v204_cellular                                       -0.149379   -0.072265   \n",
       "v204_college                                        -0.017172   -0.008307   \n",
       "v204_dialup                                         -0.017172   -0.008307   \n",
       "v204_mobile                                         -0.219503   -0.106188   \n",
       "v204_residential                                    -0.244757   -0.118406   \n",
       "v204_wifi                                            1.000000   -0.109982   \n",
       "v204_wired                                          -0.109982    1.000000   \n",
       "v204_nan                                            -0.300056   -0.145158   \n",
       "v172.1_n                                             0.059917   -0.022065   \n",
       "v172.1_p                                            -0.045610    0.040331   \n",
       "v172.1_u                                             0.270852    0.142633   \n",
       "v172.1_y                                             0.047903   -0.028984   \n",
       "v172.1_nan                                          -0.296234   -0.143308   \n",
       "\n",
       "                                                    v204_nan  v172.1_n  \\\n",
       "response                                            0.005322 -0.045414   \n",
       "v001                                                0.053279  0.018721   \n",
       "v002                                                0.046851 -0.035833   \n",
       "v4                                                  0.061015 -0.023792   \n",
       "v5                                                  0.075617 -0.008706   \n",
       "v14                                                 0.051670 -0.023801   \n",
       "v29                                                -0.012713 -0.013708   \n",
       "v120                                                0.143450 -0.024368   \n",
       "v123                                                0.063949 -0.018716   \n",
       "v173                                                0.059518 -0.074746   \n",
       "v174                                               -0.055338  0.074804   \n",
       "v175                                                0.165227 -0.215025   \n",
       "v176                                               -0.173165  0.215696   \n",
       "v177                                                0.121614 -0.150750   \n",
       "v180                                                0.227068 -0.170986   \n",
       "v181                                               -0.140203 -0.053073   \n",
       "v182                                                0.435554 -0.054048   \n",
       "v183                                                0.093479 -0.075338   \n",
       "v185                                                0.214553 -0.162560   \n",
       "v191                                               -0.122082 -0.018557   \n",
       "v192                                               -0.122082 -0.018557   \n",
       "v196                                               -0.072091 -0.010958   \n",
       "v197                                               -0.072091 -0.010958   \n",
       "v198                                                     NaN       NaN   \n",
       "v200                                               -0.099252  0.005975   \n",
       "v178_certified                                     -0.032072  0.263955   \n",
       "v178_emailinexistent                               -0.045416 -0.006903   \n",
       "v178_validdomain                                   -0.139178 -0.021156   \n",
       "v178_verified                                      -0.866443  0.038576   \n",
       "v178_nan                                            0.987261 -0.059431   \n",
       "...                                                      ...       ...   \n",
       "v193_yes                                           -0.871616  0.067180   \n",
       "v193_nan                                            0.987261 -0.059431   \n",
       "v194_yes                                           -0.987261  0.059431   \n",
       "v194_nan                                            0.987261 -0.059431   \n",
       "v195_low                                           -0.072091 -0.010958   \n",
       "v195_moderate                                      -0.955916  0.061350   \n",
       "v195_nan                                            0.987261 -0.059431   \n",
       "v199_moderate                                      -0.987261  0.059431   \n",
       "v199_nan                                            0.987261 -0.059431   \n",
       "v201_moderate by proxy reputation and country code -0.996813  0.060006   \n",
       "v201_moderate risk                                  0.099252 -0.005975   \n",
       "v201_nan                                            0.987261 -0.059431   \n",
       "v202_good                                          -0.987261  0.059431   \n",
       "v202_nan                                            0.987261 -0.059431   \n",
       "v203_no                                            -0.987261  0.059431   \n",
       "v203_nan                                            0.987261 -0.059431   \n",
       "v204_business                                      -0.045416 -0.006903   \n",
       "v204_cellular                                      -0.197154  0.065831   \n",
       "v204_college                                       -0.022664 -0.003445   \n",
       "v204_dialup                                        -0.022664 -0.003445   \n",
       "v204_mobile                                        -0.289705 -0.008062   \n",
       "v204_residential                                   -0.323037 -0.015467   \n",
       "v204_wifi                                          -0.300056  0.059917   \n",
       "v204_wired                                         -0.145158 -0.022065   \n",
       "v204_nan                                            1.000000 -0.060197   \n",
       "v172.1_n                                           -0.060197  1.000000   \n",
       "v172.1_p                                           -0.060197 -0.009150   \n",
       "v172.1_u                                           -0.909306 -0.141990   \n",
       "v172.1_y                                           -0.079076 -0.012020   \n",
       "v172.1_nan                                          0.987261 -0.059431   \n",
       "\n",
       "                                                    v172.1_p  v172.1_u  \\\n",
       "response                                           -0.010143  0.009589   \n",
       "v001                                                0.039101 -0.055188   \n",
       "v002                                               -0.040280 -0.022865   \n",
       "v4                                                 -0.031783 -0.048033   \n",
       "v5                                                 -0.048088 -0.061443   \n",
       "v14                                                -0.032463 -0.039713   \n",
       "v29                                                -0.061391  0.019671   \n",
       "v120                                               -0.015127 -0.134820   \n",
       "v123                                               -0.016883 -0.055532   \n",
       "v173                                               -0.059899 -0.015655   \n",
       "v174                                                0.058405  0.011945   \n",
       "v175                                               -0.271529  0.040504   \n",
       "v176                                                0.269962 -0.032460   \n",
       "v177                                                0.016069 -0.030689   \n",
       "v180                                               -0.175666 -0.053170   \n",
       "v181                                               -0.053073  0.163087   \n",
       "v182                                               -0.085544 -0.364803   \n",
       "v183                                               -0.075338 -0.017642   \n",
       "v185                                               -0.190442 -0.041469   \n",
       "v191                                               -0.018557  0.130693   \n",
       "v192                                               -0.018557  0.130693   \n",
       "v196                                               -0.010958  0.077176   \n",
       "v197                                               -0.010958  0.077176   \n",
       "v198                                                     NaN       NaN   \n",
       "v200                                                0.005975 -0.042078   \n",
       "v178_certified                                      0.263955 -0.075650   \n",
       "v178_emailinexistent                               -0.006903  0.048620   \n",
       "v178_validdomain                                   -0.021156  0.148996   \n",
       "v178_verified                                       0.038576  0.811306   \n",
       "v178_nan                                           -0.059431 -0.922211   \n",
       "...                                                      ...       ...   \n",
       "v193_yes                                            0.067180  0.804728   \n",
       "v193_nan                                           -0.059431 -0.922211   \n",
       "v194_yes                                            0.059431  0.922211   \n",
       "v194_nan                                           -0.059431 -0.922211   \n",
       "v195_low                                           -0.010958  0.077176   \n",
       "v195_moderate                                       0.061350  0.890484   \n",
       "v195_nan                                           -0.059431 -0.922211   \n",
       "v199_moderate                                       0.059431  0.922211   \n",
       "v199_nan                                           -0.059431 -0.922211   \n",
       "v201_moderate by proxy reputation and country code  0.060006  0.912504   \n",
       "v201_moderate risk                                 -0.005975  0.042078   \n",
       "v201_nan                                           -0.059431 -0.922211   \n",
       "v202_good                                           0.059431  0.922211   \n",
       "v202_nan                                           -0.059431 -0.922211   \n",
       "v203_no                                             0.059431  0.922211   \n",
       "v203_nan                                           -0.059431 -0.922211   \n",
       "v204_business                                      -0.006903  0.048620   \n",
       "v204_cellular                                       0.065831  0.152270   \n",
       "v204_college                                       -0.003445  0.024262   \n",
       "v204_dialup                                        -0.003445  0.024262   \n",
       "v204_mobile                                        -0.008062  0.280704   \n",
       "v204_residential                                    0.051805  0.290778   \n",
       "v204_wifi                                          -0.045610  0.270852   \n",
       "v204_wired                                          0.040331  0.142633   \n",
       "v204_nan                                           -0.060197 -0.909306   \n",
       "v172.1_n                                           -0.009150 -0.141990   \n",
       "v172.1_p                                            1.000000 -0.141990   \n",
       "v172.1_u                                           -0.141990  1.000000   \n",
       "v172.1_y                                           -0.012020 -0.186519   \n",
       "v172.1_nan                                         -0.059431 -0.922211   \n",
       "\n",
       "                                                    v172.1_y  v172.1_nan  \n",
       "response                                           -0.032629    0.010840  \n",
       "v001                                               -0.057636    0.060728  \n",
       "v002                                                0.002458    0.039053  \n",
       "v4                                                 -0.000563    0.061561  \n",
       "v5                                                 -0.012874    0.079078  \n",
       "v14                                                 0.001402    0.052564  \n",
       "v29                                                 0.023207   -0.010858  \n",
       "v120                                                0.006430    0.145945  \n",
       "v123                                               -0.007136    0.066902  \n",
       "v173                                               -0.058134    0.060699  \n",
       "v174                                                0.057632   -0.056421  \n",
       "v175                                               -0.369961    0.163113  \n",
       "v176                                                0.369446   -0.171096  \n",
       "v177                                               -0.217245    0.120156  \n",
       "v180                                               -0.348206    0.224360  \n",
       "v181                                               -0.027995   -0.138417  \n",
       "v182                                               -0.108406    0.436544  \n",
       "v183                                               -0.152879    0.092288  \n",
       "v185                                               -0.341731    0.211820  \n",
       "v191                                               -0.024377   -0.120527  \n",
       "v192                                               -0.024377   -0.120527  \n",
       "v196                                               -0.014395   -0.071173  \n",
       "v197                                               -0.014395   -0.071173  \n",
       "v198                                                     NaN         NaN  \n",
       "v200                                                0.007848    0.038805  \n",
       "v178_certified                                     -0.006404   -0.031664  \n",
       "v178_emailinexistent                               -0.009068   -0.044837  \n",
       "v178_validdomain                                   -0.027790   -0.137405  \n",
       "v178_verified                                       0.088766   -0.879486  \n",
       "v178_nan                                           -0.078068    1.000000  \n",
       "...                                                      ...         ...  \n",
       "v193_yes                                            0.088249   -0.884640  \n",
       "v193_nan                                           -0.078068    1.000000  \n",
       "v194_yes                                            0.078068   -1.000000  \n",
       "v194_nan                                           -0.078068    1.000000  \n",
       "v195_low                                           -0.014395   -0.071173  \n",
       "v195_moderate                                       0.080590   -0.968711  \n",
       "v195_nan                                           -0.078068    1.000000  \n",
       "v199_moderate                                       0.078068   -1.000000  \n",
       "v199_nan                                           -0.078068    1.000000  \n",
       "v201_moderate by proxy reputation and country code  0.078824   -0.990417  \n",
       "v201_moderate risk                                 -0.007848   -0.038805  \n",
       "v201_nan                                           -0.078068    1.000000  \n",
       "v202_good                                           0.078068   -1.000000  \n",
       "v202_nan                                           -0.078068    1.000000  \n",
       "v203_no                                             0.078068   -1.000000  \n",
       "v203_nan                                           -0.078068    1.000000  \n",
       "v204_business                                      -0.009068   -0.044837  \n",
       "v204_cellular                                       0.034042   -0.194643  \n",
       "v204_college                                       -0.004525   -0.022375  \n",
       "v204_dialup                                        -0.004525   -0.022375  \n",
       "v204_mobile                                        -0.002714   -0.286015  \n",
       "v204_residential                                    0.038595   -0.318922  \n",
       "v204_wifi                                           0.047903   -0.296234  \n",
       "v204_wired                                         -0.028984   -0.143308  \n",
       "v204_nan                                           -0.079076    0.987261  \n",
       "v172.1_n                                           -0.012020   -0.059431  \n",
       "v172.1_p                                           -0.012020   -0.059431  \n",
       "v172.1_u                                           -0.186519   -0.922211  \n",
       "v172.1_y                                            1.000000   -0.078068  \n",
       "v172.1_nan                                         -0.078068    1.000000  \n",
       "\n",
       "[71 rows x 71 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = dataset_normalized.corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting a list (series) of correlations between the target and all features. I am interested in magnitude, so I will take absoulute values. Then I will sort them in descending order. Items in the top of the list are likely to be more important factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response                                              1.000000\n",
       "v192                                                  0.194025\n",
       "v191                                                  0.194025\n",
       "v29                                                   0.172579\n",
       "v204_wifi                                             0.148913\n",
       "v204_business                                         0.105443\n",
       "v204_cellular                                         0.097367\n",
       "v204_residential                                      0.077241\n",
       "v002                                                  0.072353\n",
       "v182                                                  0.066963\n",
       "v120                                                  0.051613\n",
       "v177                                                  0.048428\n",
       "v172.1_n                                              0.045414\n",
       "v174                                                  0.044762\n",
       "v173                                                  0.042317\n",
       "v195_low                                              0.034318\n",
       "v197                                                  0.034318\n",
       "v196                                                  0.034318\n",
       "v172.1_y                                              0.032629\n",
       "v201_moderate risk                                    0.029653\n",
       "v200                                                  0.029653\n",
       "v181                                                  0.026332\n",
       "v204_mobile                                           0.024923\n",
       "v178_certified                                        0.024196\n",
       "v180                                                  0.022540\n",
       "v193_yes                                              0.022007\n",
       "v178_validdomain                                      0.021854\n",
       "v193_not sure                                         0.021854\n",
       "v183                                                  0.021228\n",
       "v184_lower fraud risk                                 0.020346\n",
       "                                                        ...   \n",
       "v184_data entry review                                0.012306\n",
       "v186_fraud score 601 to 799                           0.012306\n",
       "v193_no                                               0.012306\n",
       "v178_emailinexistent                                  0.012306\n",
       "v203_nan                                              0.010840\n",
       "v203_no                                               0.010840\n",
       "v202_nan                                              0.010840\n",
       "v202_good                                             0.010840\n",
       "v201_nan                                              0.010840\n",
       "v186_nan                                              0.010840\n",
       "v172.1_nan                                            0.010840\n",
       "v184_nan                                              0.010840\n",
       "v199_moderate                                         0.010840\n",
       "v195_nan                                              0.010840\n",
       "v194_nan                                              0.010840\n",
       "v194_yes                                              0.010840\n",
       "v178_nan                                              0.010840\n",
       "v193_nan                                              0.010840\n",
       "v199_nan                                              0.010840\n",
       "v172.1_p                                              0.010143\n",
       "v172.1_u                                              0.009589\n",
       "v4                                                    0.007668\n",
       "v186_fraud score 1 to 100                             0.007036\n",
       "v201_moderate by proxy reputation and country code    0.006696\n",
       "v204_nan                                              0.005322\n",
       "v204_wired                                            0.002650\n",
       "v184_moderate fraud risk                              0.002095\n",
       "v186_fraud score 301 to 600                           0.002095\n",
       "v123                                                  0.001951\n",
       "v198                                                       NaN\n",
       "Name: response, Length: 71, dtype: float64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_with_target_abs_desc = corr_matrix[target].apply(np.abs).sort_values(ascending=False)\n",
    "corr_with_target_abs_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that many features have the same correlation with the target (e.g. v191 and v192). Thus, I can exclude some redundant features (e.g. dimensionality reduction). \n",
    "Below I define a vectorized function that will exclude redundant features and return a list of 'unique' features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exclude_similar_features_and_get_unique(corr_with_target_series, similarity_thresh = 0.000001):\n",
    "    #getting 2 arrays from series - 1 array without the first element, and another without the last element\n",
    "    corr_with_target_array_less_first_el = corr_with_target_series.tail(len(corr_with_target_series)-1).values\n",
    "    corr_with_target_array_less_last_el = corr_with_target_series.head(len(corr_with_target_series)-1).values\n",
    "    \n",
    "    #calculating absoluste differences between these arrays, which is equivalent to finding difference between\n",
    "    #subsequent elements in the original series\n",
    "    corr_with_target_array_subseq_el_differences = np.abs(\n",
    "            corr_with_target_array_less_first_el - corr_with_target_array_less_last_el)\n",
    "    \n",
    "    #finding which elements has differences over similarity_thresh\n",
    "    corr_with_target_array_subseq_el_differences_over_thresh = (\n",
    "            corr_with_target_array_subseq_el_differences > similarity_thresh )\n",
    "    \n",
    "    #we will keep the first element, so assume set it to True to keep\n",
    "    first_el_diff = np.array([True])\n",
    "    corr_with_target_array_subseq_el_differences_over_thresh = np.append(\n",
    "            first_el_diff, corr_with_target_array_subseq_el_differences_over_thresh)\n",
    "    \n",
    "    #geetting boolean list that shows which elements are unique and thus should stay and which to be excluded\n",
    "    corr_with_target_array_subseq_el_differences_over_thresh_bool_list = list(\n",
    "            corr_with_target_array_subseq_el_differences_over_thresh)\n",
    "    \n",
    "    #getting a list of unique features\n",
    "    corr_with_target_series_unique = (\n",
    "            corr_with_target_series[corr_with_target_array_subseq_el_differences_over_thresh_bool_list])\n",
    "    unique_feature_list = list(corr_with_target_series_unique.index)\n",
    "    return unique_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilja.surikovs\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in greater\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "unique_features = exclude_similar_features_and_get_unique(corr_with_target_abs_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['response',\n",
       " 'v192',\n",
       " 'v29',\n",
       " 'v204_wifi',\n",
       " 'v204_business',\n",
       " 'v204_cellular',\n",
       " 'v204_residential',\n",
       " 'v002',\n",
       " 'v182',\n",
       " 'v120',\n",
       " 'v177',\n",
       " 'v172.1_n',\n",
       " 'v174',\n",
       " 'v173',\n",
       " 'v195_low',\n",
       " 'v172.1_y',\n",
       " 'v201_moderate risk',\n",
       " 'v181',\n",
       " 'v204_mobile',\n",
       " 'v178_certified',\n",
       " 'v180',\n",
       " 'v193_yes',\n",
       " 'v178_validdomain',\n",
       " 'v183',\n",
       " 'v184_lower fraud risk',\n",
       " 'v176',\n",
       " 'v186_fraud score 101 to 300',\n",
       " 'v178_verified',\n",
       " 'v195_moderate',\n",
       " 'v185',\n",
       " 'v14',\n",
       " 'v204_dialup',\n",
       " 'v001',\n",
       " 'v175',\n",
       " 'v5',\n",
       " 'v184_data entry review',\n",
       " 'v203_nan',\n",
       " 'v172.1_p',\n",
       " 'v172.1_u',\n",
       " 'v4',\n",
       " 'v186_fraud score 1 to 100',\n",
       " 'v201_moderate by proxy reputation and country code',\n",
       " 'v204_nan',\n",
       " 'v204_wired',\n",
       " 'v184_moderate fraud risk',\n",
       " 'v123']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will create a new dataset that will contain only the target and 'unique' features.\n",
    "\n",
    "_Note: in fact I have tried to run the logistic regression both with redundant features and without. The results are the same. So it is mainly about computational efficiency._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_normalized_unique_features=dataset_normalized[unique_features] # - use this to keep only unique features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_3) Trying the model with basic settings_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the strongest predictors logistic regression is a good ML-algorithm. I choose Regression, because it will expclicitly show which factors have more impact on the target and which less. I will use L2 and L1 regularization that allows to deal with collinearity and overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) I will split the data to the train and test sets. Training set will be used to train and calibrate the model. Test set is used to assess the final model. Test set is 20% of the data and train set - 80%. Random state is set to 1, so that the data is split in the same manner every time I run the split function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset_normalized_unique_features, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Creating a model. C (L2 regularization parameter) is set to 1, but will be calibrated later. I will fit intercept to have less biased coefficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(penalty='l2', C=1, fit_intercept=True, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) getting predictor names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get columns names except the target\n",
    "predictors = get_col_names_without_target(dataset_normalized_unique_features, target='response')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) I use cross validation to see what is the accuracy of the model with basic settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here I define a function to conveniently do cross-validation and print the results\n",
    "def print_scores(model, X_features, Y_target):\n",
    "    scores = cross_val_score(model, X_features, Y_target, cv=5)\n",
    "    print('accuracies =', scores)\n",
    "    print('mean accuracy =', scores.mean())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies = [ 0.80645161  0.83870968  0.76612903  0.80487805  0.83606557]\n",
      "mean accuracy = 0.810446789026\n"
     ]
    }
   ],
   "source": [
    "print_scores(log_reg, train[predictors], train[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) It is good to compare performance of my model with majority class prediction model. This is the minimum accuracy that my model should achive. Majority class naive prediction is when you predict that every record belongs to a majority class. In this case it would give the following accuracies on train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.807131280388979"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-train[target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8516129032258064"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-test[target].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My model gives essentially the same results, so it is not a very bad model, but  also not a good one. Thus, need to calibrate it further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_3) Calibrating the model_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) we have an inbalanced dataset ~ 80% of data has response value of 0 and ~20% - 1. I will try to use 'balanced' class_weight to tackle that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_reg_balanced = LogisticRegression(penalty='l2', C=1, fit_intercept=True, random_state=1, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies = [ 0.62903226  0.62096774  0.62903226  0.64227642  0.62295082]\n",
      "mean accuracy = 0.6288519001\n"
     ]
    }
   ],
   "source": [
    "print_scores(log_reg_balanced, train[predictors], train[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is actually much worse, so no need to use class_weight functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) trying Logistic Regression with L1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_reg_l1 = LogisticRegression(penalty='l1', C=1, fit_intercept=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies = [ 0.78225806  0.83870968  0.78225806  0.80487805  0.8442623 ]\n",
      "mean accuracy = 0.810473230063\n"
     ]
    }
   ],
   "source": [
    "print_scores(log_reg_l1, train[predictors], train[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log.reg. model with L1 regularization give better rezults than the majority class prediction model. It also outperforms log.reg. with L2  regularization. So, I will stick to that model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Calibration regularization parameter C. Firstly, I try a wide band of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c param = 0.01\n",
      "accuracies = [ 0.80645161  0.80645161  0.80645161  0.80487805  0.81147541]\n",
      "mean accuracy = 0.807141659465\n",
      "\n",
      "c param = 0.1\n",
      "accuracies = [ 0.80645161  0.81451613  0.80645161  0.81300813  0.83606557]\n",
      "mean accuracy = 0.815298611738\n",
      "\n",
      "c param = 0.5\n",
      "accuracies = [ 0.79032258  0.83870968  0.78225806  0.78861789  0.8442623 ]\n",
      "mean accuracy = 0.808834100768\n",
      "\n",
      "c param = 1\n",
      "accuracies = [ 0.78225806  0.83870968  0.78225806  0.80487805  0.8442623 ]\n",
      "mean accuracy = 0.810473230063\n",
      "\n",
      "c param = 2\n",
      "accuracies = [ 0.79032258  0.83870968  0.78225806  0.80487805  0.83606557]\n",
      "mean accuracy = 0.810446789026\n",
      "\n",
      "c param = 5\n",
      "accuracies = [ 0.7983871   0.83870968  0.77419355  0.79674797  0.83606557]\n",
      "mean accuracy = 0.808820772766\n",
      "\n",
      "c param = 15\n",
      "accuracies = [ 0.81451613  0.83870968  0.76612903  0.79674797  0.83606557]\n",
      "mean accuracy = 0.810433675992\n",
      "\n",
      "c param = 100\n",
      "accuracies = [ 0.81451613  0.83870968  0.76612903  0.78861789  0.81967213]\n",
      "mean accuracy = 0.805528971207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for C_param in [0.01, 0.1, 0.5, 1, 2, 5, 15, 100]:\n",
    "    log_reg_l1_diff_c = LogisticRegression(penalty='l1', C=C_param, fit_intercept=True, random_state=1)\n",
    "    print('c param =', C_param)\n",
    "    print_scores(log_reg_l1_diff_c, train[predictors], train[target])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal C parameter is somewhere between 0.1 - 1, so I will narrow down the search in this interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c param = 0.05\n",
      "accuracies = [ 0.80645161  0.80645161  0.80645161  0.80487805  0.81147541]\n",
      "mean accuracy = 0.807141659465\n",
      "\n",
      "c param = 0.1\n",
      "accuracies = [ 0.80645161  0.81451613  0.80645161  0.81300813  0.83606557]\n",
      "mean accuracy = 0.815298611738\n",
      "\n",
      "c param = 0.2\n",
      "accuracies = [ 0.80645161  0.83870968  0.7983871   0.81300813  0.83606557]\n",
      "mean accuracy = 0.81852441819\n",
      "\n",
      "c param = 0.3\n",
      "accuracies = [ 0.7983871   0.83870968  0.79032258  0.79674797  0.8442623 ]\n",
      "mean accuracy = 0.81368592348\n",
      "\n",
      "c param = 0.4\n",
      "accuracies = [ 0.7983871   0.83870968  0.78225806  0.78861789  0.8442623 ]\n",
      "mean accuracy = 0.810447003994\n",
      "\n",
      "c param = 0.5\n",
      "accuracies = [ 0.79032258  0.83870968  0.78225806  0.78861789  0.8442623 ]\n",
      "mean accuracy = 0.808834100768\n",
      "\n",
      "c param = 0.6\n",
      "accuracies = [ 0.7983871   0.83870968  0.78225806  0.78861789  0.8442623 ]\n",
      "mean accuracy = 0.810447003994\n",
      "\n",
      "c param = 0.7\n",
      "accuracies = [ 0.79032258  0.83870968  0.78225806  0.78861789  0.8442623 ]\n",
      "mean accuracy = 0.808834100768\n",
      "\n",
      "c param = 0.8\n",
      "accuracies = [ 0.78225806  0.83870968  0.78225806  0.79674797  0.8442623 ]\n",
      "mean accuracy = 0.808847213803\n",
      "\n",
      "c param = 1\n",
      "accuracies = [ 0.78225806  0.83870968  0.78225806  0.80487805  0.8442623 ]\n",
      "mean accuracy = 0.810473230063\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for C_param in [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 1]:\n",
    "    log_reg_l1_diff_c = LogisticRegression(penalty='l1', C=C_param, fit_intercept=True, random_state=1)\n",
    "    print('c param =', C_param)\n",
    "    print_scores(log_reg_l1_diff_c, train[predictors], train[target])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal value is 0.2. I will use that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Will look for optimal Tolerance for stopping criteria (tol)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tol param = 1e-08\n",
      "accuracies = [ 0.80645161  0.83870968  0.7983871   0.81300813  0.83606557]\n",
      "mean accuracy = 0.81852441819\n",
      "\n",
      "tol param = 1e-06\n",
      "accuracies = [ 0.80645161  0.83870968  0.7983871   0.81300813  0.83606557]\n",
      "mean accuracy = 0.81852441819\n",
      "\n",
      "tol param = 0.0001\n",
      "accuracies = [ 0.80645161  0.83870968  0.7983871   0.81300813  0.83606557]\n",
      "mean accuracy = 0.81852441819\n",
      "\n",
      "tol param = 0.01\n",
      "accuracies = [ 0.80645161  0.83870968  0.7983871   0.81300813  0.83606557]\n",
      "mean accuracy = 0.81852441819\n",
      "\n",
      "tol param = 0.1\n",
      "accuracies = [ 0.80645161  0.83870968  0.7983871   0.81300813  0.83606557]\n",
      "mean accuracy = 0.81852441819\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tol in [1e-8, 1e-6, 1e-4, 1e-2, 1e-1]:\n",
    "    log_reg_l1_diff_tol = LogisticRegression(penalty='l1', C=0.2, tol = tol, fit_intercept=True, random_state=1)\n",
    "    print('tol param =', tol)\n",
    "    print_scores(log_reg_l1_diff_tol, train[predictors], train[target])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All give the same results, so I will stick to the default value of 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) I will perform cross-validation of the model with optimal parameters on the training set. Then, will check it's performance on the whole train set and the check it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies = [ 0.80645161  0.81451613  0.80645161  0.81300813  0.83606557]\n",
      "mean accuracy = 0.815298611738\n"
     ]
    }
   ],
   "source": [
    "# cross validation on train set\n",
    "log_reg_final = LogisticRegression(penalty='l1', C=0.1, fit_intercept=True, random_state=1)\n",
    "print_scores(log_reg_final, train[predictors], train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8233387358184765"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model on train-set and evaluate on train set\n",
    "log_reg_final.fit(train[predictors], train[target])\n",
    "log_reg_final.score(train[predictors], train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85161290322580641"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check model on the test set\n",
    "log_reg_final.score(test[predictors], test[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is consistent (from 0.80 to 0.85). Model is not overfitting, since the score on the whole train set is 0.82 which is consistent with other scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_4) Determening the key factors with the final model_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Will train the model on the whole dataset and check the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82901554404145072"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_set = dataset_normalized_unique_features\n",
    "log_reg_final.fit(full_set[predictors], full_set[target])\n",
    "log_reg_final.score(full_set[predictors], full_set[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) getting the coefficients on the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coef_array = log_reg_final.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coef_series = pd.Series(coef_array[0], predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly as with correlation coefficients, I will get the absolute values and sort them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_coefficients = coef_series.apply(np.abs).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the list of factors from the most important factor (v29) to the least important factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v29                                                   0.455469\n",
       "v204_wifi                                             0.294803\n",
       "v192                                                  0.287484\n",
       "v204_business                                         0.111842\n",
       "v182                                                  0.104633\n",
       "v120                                                  0.095231\n",
       "v204_cellular                                         0.082976\n",
       "v195_low                                              0.050899\n",
       "v204_residential                                      0.049155\n",
       "v4                                                    0.031744\n",
       "v181                                                  0.030117\n",
       "v172.1_n                                              0.016092\n",
       "v002                                                  0.012492\n",
       "v177                                                  0.004003\n",
       "v173                                                  0.000000\n",
       "v174                                                  0.000000\n",
       "v172.1_y                                              0.000000\n",
       "v201_moderate risk                                    0.000000\n",
       "v178_validdomain                                      0.000000\n",
       "v204_mobile                                           0.000000\n",
       "v178_certified                                        0.000000\n",
       "v180                                                  0.000000\n",
       "v193_yes                                              0.000000\n",
       "v123                                                  0.000000\n",
       "v184_moderate fraud risk                              0.000000\n",
       "v5                                                    0.000000\n",
       "v204_wired                                            0.000000\n",
       "v204_nan                                              0.000000\n",
       "v201_moderate by proxy reputation and country code    0.000000\n",
       "v186_fraud score 1 to 100                             0.000000\n",
       "v172.1_u                                              0.000000\n",
       "v172.1_p                                              0.000000\n",
       "v203_nan                                              0.000000\n",
       "v184_data entry review                                0.000000\n",
       "v175                                                  0.000000\n",
       "v184_lower fraud risk                                 0.000000\n",
       "v001                                                  0.000000\n",
       "v204_dialup                                           0.000000\n",
       "v14                                                   0.000000\n",
       "v185                                                  0.000000\n",
       "v195_moderate                                         0.000000\n",
       "v178_verified                                         0.000000\n",
       "v186_fraud score 101 to 300                           0.000000\n",
       "v176                                                  0.000000\n",
       "v183                                                  0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will take the top 15 factors and visualize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top15_coef = sorted_coefficients[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fcfdd4f1d0>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAAHxCAYAAAAsmV6DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIiIGBL/D72nul3w/PbzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fcfdd71da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top15_coef.plot(figsize=(15,7), use_index=True, grid=True, legend=False, \n",
    "                xticks=np.arange(len(top15_coef)),\n",
    "                rot=45,\n",
    "                title = 'Most important predictors',\n",
    "                kind='bar',\n",
    "                fontsize=12,\n",
    "                colormap='Set1',\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important predictors are v29, v204\\*, v192, v182, v120, v195_Low\\**, v4. \n",
    "\n",
    "These findings are consistent with the correlation table obtained earlier. The former showed consistent results, where v192, v29, v204, v182, and v120 are top factors as well.\n",
    "\n",
    "Because of similarity/redundancy I have excluded some factors earlier. Most importantly, I have excluded v191 (which is identical to v192). But, I could say that v191 is also an important regressor. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\* from which I created several dummies. Important ones are - v204_wifi, v204_business, v204_residential, v204_cellular; and not important - v204_mobile, v204_nan, v204_wired. But overall I can conclude that this feature is important.\n",
    "\n",
    "\\** Below I will do some F-tests, to check if some of the factors are important statistically. It is not really part of ML-approach, it is more out of curiosity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) extra section - performing F tests on various predictors to assess their statistical significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f_regression is used to performa F tests. For the chosen predictors or groups of predictors I will show p-values of F-scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3409731,  0.5936604])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_regression(full_set[['v195_low','v195_moderate']],full_set[target])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v195 - does not appear to be a statistically significatn factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.41016123e-06])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_regression(full_set[['v29']],full_set[target])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.51245921e-08])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_regression(full_set[['v192']],full_set[target])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v29 and v129 - do appear to be a statistically significant factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I will use RandomForestClassifier model to do the predictions. It is a very powerful model both theoretically and empirically. It works well against ovefitting. At the same time, it has only few parameters that are not too sensitive too changes. So, it is relatively easy to calibrate them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I will use the same train and test set from Task 2. It will save space and it will allow to compare Random Forest model with Logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ 1) Random_Forest with default parameters. __"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "(a) creating a model with default parameters. Exception - random_state=1 to get the same results for different runs. n_jobs=-1 - utilizing all the cores, it will increase speed, but does not affect accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Random_Forest_model = RandomForestClassifier(n_jobs=-1, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "(b) cross-validation with basic setings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies = [ 0.75806452  0.78225806  0.80645161  0.81300813  0.80327869]\n",
      "mean accuracy = 0.792612202431\n"
     ]
    }
   ],
   "source": [
    "print_scores(Random_Forest_model, train[predictors], train[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are not better than simply predicting the majority class. Also, the optimized logistic regression was giving better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ 2) Calibrating the model - Part A, looking at paremeters separately__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Firstly will try with the number of trees to be built (n_estimators)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 1\n",
      "accuracies = [ 0.66129032  0.71774194  0.71774194  0.77235772  0.71311475]\n",
      "mean accuracy = 0.716449334245\n",
      "\n",
      "n_estimators = 5\n",
      "accuracies = [ 0.75806452  0.75806452  0.76612903  0.80487805  0.81147541]\n",
      "mean accuracy = 0.779722304627\n",
      "\n",
      "n_estimators = 10\n",
      "accuracies = [ 0.75806452  0.78225806  0.80645161  0.81300813  0.80327869]\n",
      "mean accuracy = 0.792612202431\n",
      "\n",
      "n_estimators = 30\n",
      "accuracies = [ 0.79032258  0.82258065  0.79032258  0.82926829  0.81147541]\n",
      "mean accuracy = 0.808793901794\n",
      "\n",
      "n_estimators = 50\n",
      "accuracies = [ 0.79032258  0.81451613  0.80645161  0.82113821  0.83606557]\n",
      "mean accuracy = 0.813698821547\n",
      "\n",
      "n_estimators = 70\n",
      "accuracies = [ 0.7983871   0.80645161  0.81451613  0.82113821  0.83606557]\n",
      "mean accuracy = 0.815311724772\n",
      "\n",
      "n_estimators = 100\n",
      "accuracies = [ 0.79032258  0.81451613  0.82258065  0.80487805  0.81967213]\n",
      "mean accuracy = 0.810393906953\n",
      "\n",
      "n_estimators = 120\n",
      "accuracies = [ 0.79032258  0.81451613  0.7983871   0.80487805  0.82786885]\n",
      "mean accuracy = 0.807194541538\n",
      "\n",
      "n_estimators = 150\n",
      "accuracies = [ 0.79032258  0.81451613  0.7983871   0.80487805  0.82786885]\n",
      "mean accuracy = 0.807194541538\n",
      "\n",
      "n_estimators = 200\n",
      "accuracies = [ 0.79032258  0.81451613  0.7983871   0.80487805  0.82786885]\n",
      "mean accuracy = 0.807194541538\n",
      "\n",
      "n_estimators = 300\n",
      "accuracies = [ 0.79032258  0.80645161  0.80645161  0.81300813  0.81967213]\n",
      "mean accuracy = 0.807181213536\n",
      "\n",
      "n_estimators = 500\n",
      "accuracies = [ 0.7983871   0.80645161  0.80645161  0.82113821  0.81967213]\n",
      "mean accuracy = 0.810420133022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n_estimators in [1, 5, 10, 30, 50, 70, 100, 120, 150, 200, 300, 500]:\n",
    "    Random_Forest_model = RandomForestClassifier(n_estimators=n_estimators, n_jobs=-1, random_state=1)\n",
    "    print('n_estimators =', n_estimators)\n",
    "    print_scores(Random_Forest_model, train[predictors], train[target])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "50, 70 and 100 seems to be the best. Will stick to 50 for time-being. With less trees to built, the model will work faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Optimize the min number of observations needed to do the split (min_samples_split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples_split = 2\n",
      "accuracies = [ 0.79032258  0.81451613  0.80645161  0.82113821  0.83606557]\n",
      "mean accuracy = 0.813698821547\n",
      "\n",
      "min_samples_split = 3\n",
      "accuracies = [ 0.80645161  0.81451613  0.81451613  0.81300813  0.81147541]\n",
      "mean accuracy = 0.811993482177\n",
      "\n",
      "min_samples_split = 5\n",
      "accuracies = [ 0.78225806  0.81451613  0.81451613  0.82926829  0.82786885]\n",
      "mean accuracy = 0.813685493545\n",
      "\n",
      "min_samples_split = 7\n",
      "accuracies = [ 0.79032258  0.81451613  0.81451613  0.82113821  0.81967213]\n",
      "mean accuracy = 0.812033036248\n",
      "\n",
      "min_samples_split = 10\n",
      "accuracies = [ 0.81451613  0.81451613  0.81451613  0.81300813  0.8442623 ]\n",
      "mean accuracy = 0.820163762452\n",
      "\n",
      "min_samples_split = 12\n",
      "accuracies = [ 0.78225806  0.80645161  0.80645161  0.81300813  0.81967213]\n",
      "mean accuracy = 0.80556831031\n",
      "\n",
      "min_samples_split = 15\n",
      "accuracies = [ 0.80645161  0.80645161  0.81451613  0.81300813  0.82786885]\n",
      "mean accuracy = 0.813659267476\n",
      "\n",
      "min_samples_split = 20\n",
      "accuracies = [ 0.7983871   0.80645161  0.80645161  0.82113821  0.81147541]\n",
      "mean accuracy = 0.80878078876\n",
      "\n",
      "min_samples_split = 30\n",
      "accuracies = [ 0.80645161  0.80645161  0.80645161  0.81300813  0.81967213]\n",
      "mean accuracy = 0.810407019988\n",
      "\n",
      "min_samples_split = 50\n",
      "accuracies = [ 0.80645161  0.80645161  0.7983871   0.80487805  0.81147541]\n",
      "mean accuracy = 0.805528756239\n",
      "\n",
      "min_samples_split = 70\n",
      "accuracies = [ 0.80645161  0.80645161  0.80645161  0.80487805  0.81147541]\n",
      "mean accuracy = 0.807141659465\n",
      "\n",
      "min_samples_split = 100\n",
      "accuracies = [ 0.80645161  0.80645161  0.80645161  0.80487805  0.81147541]\n",
      "mean accuracy = 0.807141659465\n",
      "\n",
      "min_samples_split = 150\n",
      "accuracies = [ 0.80645161  0.80645161  0.80645161  0.80487805  0.81147541]\n",
      "mean accuracy = 0.807141659465\n",
      "\n",
      "min_samples_split = 250\n",
      "accuracies = [ 0.80645161  0.80645161  0.80645161  0.80487805  0.81147541]\n",
      "mean accuracy = 0.807141659465\n",
      "\n",
      "min_samples_split = 500\n",
      "accuracies = [ 0.80645161  0.80645161  0.80645161  0.80487805  0.81147541]\n",
      "mean accuracy = 0.807141659465\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for min_samples_split in [2, 3, 5, 7, 10, 12, 15, 20, 30, 50, 70, 100, 150, 250, 500]:\n",
    "    Random_Forest_model = RandomForestClassifier(min_samples_split=min_samples_split, n_estimators=50, n_jobs=-1, random_state=1)\n",
    "    print('min_samples_split =', min_samples_split)\n",
    "    print_scores(Random_Forest_model, train[predictors], train[target])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "10 seems to be optimal, will stick to that for some time. Later will need to do a grid search with several parameters at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Optimize class_weight parameters - whether to adjust weights due to class disbalance or no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_weight = None\n",
      "accuracies = [ 0.81451613  0.81451613  0.81451613  0.81300813  0.8442623 ]\n",
      "mean accuracy = 0.820163762452\n",
      "\n",
      "class_weight = balanced\n",
      "accuracies = [ 0.75806452  0.81451613  0.76612903  0.7804878   0.81967213]\n",
      "mean accuracy = 0.787773922689\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for class_weight in [None, 'balanced']:\n",
    "    Random_Forest_model = RandomForestClassifier(class_weight=class_weight, min_samples_split=10, \n",
    "                                                 n_estimators=50, n_jobs=-1, random_state=1)\n",
    "    print('class_weight =', class_weight)\n",
    "    print_scores(Random_Forest_model, train[predictors], train[target])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "None is better, thus will stick to default class_weight=None."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Whether bootstrap samples are used when building trees or no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap = True\n",
      "accuracies = [ 0.81451613  0.81451613  0.81451613  0.81300813  0.8442623 ]\n",
      "mean accuracy = 0.820163762452\n",
      "\n",
      "bootstrap = False\n",
      "accuracies = [ 0.7983871   0.80645161  0.7983871   0.82926829  0.80327869]\n",
      "mean accuracy = 0.807154557532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for bootstrap in [True, False]:\n",
    "    Random_Forest_model = RandomForestClassifier(bootstrap=bootstrap, min_samples_split=10, \n",
    "                                                 n_estimators=50, n_jobs=-1, random_state=1)\n",
    "    print('bootstrap =', bootstrap)\n",
    "    print_scores(Random_Forest_model, train[predictors], train[target])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Will use the default, bootstrap=True, it is a bit better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Whether to use out-of-bag samples to estimate the generalization accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oob_score = True\n",
      "accuracies = [ 0.81451613  0.81451613  0.81451613  0.81300813  0.8442623 ]\n",
      "mean accuracy = 0.820163762452\n",
      "\n",
      "oob_score = False\n",
      "accuracies = [ 0.81451613  0.81451613  0.81451613  0.81300813  0.8442623 ]\n",
      "mean accuracy = 0.820163762452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for oob_score in [True, False]:\n",
    "    Random_Forest_model = RandomForestClassifier(oob_score=oob_score, min_samples_split=10, \n",
    "                                                 n_estimators=50, n_jobs=-1, random_state=1)\n",
    "    print('oob_score =', oob_score)\n",
    "    print_scores(Random_Forest_model, train[predictors], train[target])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "No difference. Will use the default, oob_score=False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) criterion - the function to measure the quality of a split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion = entropy\n",
      "accuracies = [ 0.7983871   0.80645161  0.82258065  0.82113821  0.82786885]\n",
      "mean accuracy = 0.815285283736\n",
      "\n",
      "criterion = gini\n",
      "accuracies = [ 0.81451613  0.81451613  0.81451613  0.81300813  0.8442623 ]\n",
      "mean accuracy = 0.820163762452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for criterion in ['entropy', 'gini']:\n",
    "    Random_Forest_model = RandomForestClassifier(criterion=criterion, min_samples_split=10, \n",
    "                                                 n_estimators=50, n_jobs=-1, random_state=1)\n",
    "    print('criterion =', criterion)\n",
    "    print_scores(Random_Forest_model, train[predictors], train[target])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The default's 'gini' is better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(g) max_features - the number of features to consider when looking for the best split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features = auto\n",
      "accuracies = [ 0.81451613  0.81451613  0.81451613  0.81300813  0.8442623 ]\n",
      "mean accuracy = 0.820163762452\n",
      "\n",
      "max_features = sqrt\n",
      "accuracies = [ 0.81451613  0.81451613  0.81451613  0.81300813  0.8442623 ]\n",
      "mean accuracy = 0.820163762452\n",
      "\n",
      "max_features = log2\n",
      "accuracies = [ 0.79032258  0.81451613  0.80645161  0.82926829  0.83606557]\n",
      "mean accuracy = 0.815324837807\n",
      "\n",
      "max_features = None\n",
      "accuracies = [ 0.78225806  0.83870968  0.7983871   0.80487805  0.81147541]\n",
      "mean accuracy = 0.807141659465\n",
      "\n",
      "max_features = 0.1\n",
      "accuracies = [ 0.7983871   0.80645161  0.83064516  0.82113821  0.82786885]\n",
      "mean accuracy = 0.816898186962\n",
      "\n",
      "max_features = 0.25\n",
      "accuracies = [ 0.79032258  0.81451613  0.79032258  0.82113821  0.81967213]\n",
      "mean accuracy = 0.80719432657\n",
      "\n",
      "max_features = 0.5\n",
      "accuracies = [ 0.78225806  0.81451613  0.79032258  0.80487805  0.82786885]\n",
      "mean accuracy = 0.803968735087\n",
      "\n",
      "max_features = 0.75\n",
      "accuracies = [ 0.76612903  0.81451613  0.7983871   0.81300813  0.81147541]\n",
      "mean accuracy = 0.800703159596\n",
      "\n",
      "max_features = 1.0\n",
      "accuracies = [ 0.78225806  0.83870968  0.7983871   0.80487805  0.81147541]\n",
      "mean accuracy = 0.807141659465\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for max_features in ['auto', 'sqrt', 'log2', None, 0.1, 0.25, 0.5, 0.75, 1.0]:\n",
    "    Random_Forest_model = RandomForestClassifier(max_features=max_features, min_samples_split=10, \n",
    "                                                 n_estimators=50, n_jobs=-1, random_state=1)\n",
    "    print('max_features =', max_features)\n",
    "    print_scores(Random_Forest_model, train[predictors], train[target])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The default's 'auto' is the best. But will try with the number of features as integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features = 1\n",
      "accuracies = [ 0.79032258  0.82258065  0.82258065  0.81300813  0.82786885]\n",
      "mean accuracy = 0.815272170702\n",
      "\n",
      "max_features = 2\n",
      "accuracies = [ 0.80645161  0.81451613  0.82258065  0.81300813  0.81147541]\n",
      "mean accuracy = 0.813606385403\n",
      "\n",
      "max_features = 3\n",
      "accuracies = [ 0.7983871   0.82258065  0.83870968  0.81300813  0.81967213]\n",
      "mean accuracy = 0.818471536117\n",
      "\n",
      "max_features = 5\n",
      "accuracies = [ 0.79032258  0.81451613  0.80645161  0.82926829  0.83606557]\n",
      "mean accuracy = 0.815324837807\n",
      "\n",
      "max_features = 10\n",
      "accuracies = [ 0.7983871   0.80645161  0.79032258  0.79674797  0.81147541]\n",
      "mean accuracy = 0.800676933528\n",
      "\n",
      "max_features = 20\n",
      "accuracies = [ 0.7983871   0.80645161  0.80645161  0.81300813  0.82786885]\n",
      "mean accuracy = 0.810433461024\n",
      "\n",
      "max_features = 30\n",
      "accuracies = [ 0.78225806  0.82258065  0.78225806  0.82113821  0.81147541]\n",
      "mean accuracy = 0.803942079082\n",
      "\n",
      "max_features = 40\n",
      "accuracies = [ 0.77419355  0.83064516  0.7983871   0.82113821  0.81147541]\n",
      "mean accuracy = 0.807167885534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for max_features in [1, 2, 3, 5, 10, 20, 30, 40]:\n",
    "    Random_Forest_model = RandomForestClassifier(max_features=max_features, min_samples_split=10, \n",
    "                                                 n_estimators=50, n_jobs=-1, random_state=1)\n",
    "    print('max_features =', max_features)\n",
    "    print_scores(Random_Forest_model, train[predictors], train[target])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "'auto' is still better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(h) The maximum depth of the tree.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth  = 1\n",
      "accuracies = [ 0.80645161  0.80645161  0.80645161  0.80487805  0.81147541]\n",
      "mean accuracy = 0.807141659465\n",
      "\n",
      "max_depth  = 3\n",
      "accuracies = [ 0.80645161  0.80645161  0.80645161  0.80487805  0.81147541]\n",
      "mean accuracy = 0.807141659465\n",
      "\n",
      "max_depth  = 5\n",
      "accuracies = [ 0.80645161  0.80645161  0.80645161  0.80487805  0.81147541]\n",
      "mean accuracy = 0.807141659465\n",
      "\n",
      "max_depth  = 10\n",
      "accuracies = [ 0.79032258  0.80645161  0.80645161  0.81300813  0.81967213]\n",
      "mean accuracy = 0.807181213536\n",
      "\n",
      "max_depth  = 15\n",
      "accuracies = [ 0.81451613  0.80645161  0.81451613  0.82113821  0.83606557]\n",
      "mean accuracy = 0.818537531224\n",
      "\n",
      "max_depth  = 20\n",
      "accuracies = [ 0.81451613  0.81451613  0.81451613  0.81300813  0.83606557]\n",
      "mean accuracy = 0.81852441819\n",
      "\n",
      "max_depth  = 30\n",
      "accuracies = [ 0.81451613  0.81451613  0.81451613  0.81300813  0.8442623 ]\n",
      "mean accuracy = 0.820163762452\n",
      "\n",
      "max_depth  = 50\n",
      "accuracies = [ 0.81451613  0.81451613  0.81451613  0.81300813  0.8442623 ]\n",
      "mean accuracy = 0.820163762452\n",
      "\n",
      "max_depth  = 100\n",
      "accuracies = [ 0.81451613  0.81451613  0.81451613  0.81300813  0.8442623 ]\n",
      "mean accuracy = 0.820163762452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for max_depth in [1, 3, 5, 10, 15, 20, 30, 50, 100]:\n",
    "    Random_Forest_model = RandomForestClassifier(max_depth=max_depth, min_samples_split=10, \n",
    "                                                 n_estimators=50, n_jobs=-1, random_state=1)\n",
    "    print('max_depth  =', max_depth )\n",
    "    print_scores(Random_Forest_model, train[predictors], train[target])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "30 seems optimal. Will choose it for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(j) max_leaf_nodes  - the max number of leaf nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_leaf_nodes = 2\n",
      "accuracies = [ 0.80645161  0.80645161  0.80645161  0.80487805  0.81147541]\n",
      "mean accuracy = 0.807141659465\n",
      "\n",
      "max_leaf_nodes = 5\n",
      "accuracies = [ 0.80645161  0.80645161  0.80645161  0.80487805  0.81147541]\n",
      "mean accuracy = 0.807141659465\n",
      "\n",
      "max_leaf_nodes = 10\n",
      "accuracies = [ 0.80645161  0.80645161  0.81451613  0.80487805  0.81147541]\n",
      "mean accuracy = 0.808754562691\n",
      "\n",
      "max_leaf_nodes = 20\n",
      "accuracies = [ 0.7983871   0.80645161  0.83064516  0.81300813  0.81967213]\n",
      "mean accuracy = 0.813632826439\n",
      "\n",
      "max_leaf_nodes = 50\n",
      "accuracies = [ 0.7983871   0.80645161  0.82258065  0.82113821  0.81967213]\n",
      "mean accuracy = 0.813645939474\n",
      "\n",
      "max_leaf_nodes = 100\n",
      "accuracies = [ 0.7983871   0.80645161  0.82258065  0.82113821  0.81967213]\n",
      "mean accuracy = 0.813645939474\n",
      "\n",
      "max_leaf_nodes = 200\n",
      "accuracies = [ 0.7983871   0.80645161  0.82258065  0.82113821  0.81967213]\n",
      "mean accuracy = 0.813645939474\n",
      "\n",
      "max_leaf_nodes = 500\n",
      "accuracies = [ 0.7983871   0.80645161  0.82258065  0.82113821  0.81967213]\n",
      "mean accuracy = 0.813645939474\n",
      "\n",
      "max_leaf_nodes = 600\n",
      "accuracies = [ 0.7983871   0.80645161  0.82258065  0.82113821  0.81967213]\n",
      "mean accuracy = 0.813645939474\n",
      "\n",
      "max_leaf_nodes = None\n",
      "accuracies = [ 0.81451613  0.81451613  0.81451613  0.81300813  0.8442623 ]\n",
      "mean accuracy = 0.820163762452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for max_leaf_nodes in [2, 5, 10, 20, 50, 100, 200, 500, 600, None]:\n",
    "    Random_Forest_model = RandomForestClassifier(max_leaf_nodes=max_leaf_nodes, max_depth=30, min_samples_split=10, \n",
    "                                                 n_estimators=50, n_jobs=-1, random_state=1)\n",
    "    print('max_leaf_nodes =', max_leaf_nodes)\n",
    "    print_scores(Random_Forest_model, train[predictors], train[target])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The default's None is better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ 2) Calibrating the model - Part B, optimizing some parameters together with grid search__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Many parameters are interelated. In RandomForest models parameters like max_depth, min_leafs_at_split, number of trees are all aimed at reducing overfitting in one way or another. Thus, it is very useful to try them simultaniously. Of course, it is very computationally expensive to estimate all of them together and to try many values. Thus, I will use only some of those I have obtained in Part A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Firstly I define parameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid_1 = {\n",
    "    'min_samples_split':[2,5,10,20],\n",
    "    'max_features':['auto',1,2,'log2'],\n",
    "    'max_depth':[5, 20, 30, 100, None]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search_1 = GridSearchCV(estimator = RandomForestClassifier(n_estimators = 50,                                                                \n",
    "                                                              max_depth=30,\n",
    "                                                              random_state=1, n_jobs=-1), \n",
    "         param_grid = param_grid_1, scoring='accuracy', n_jobs=-1, iid=False, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilja.surikovs\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.81038, std: 0.00335, params: {'max_depth': 5, 'max_features': 'auto', 'min_samples_split': 2},\n",
       "  mean: 0.81038, std: 0.00335, params: {'max_depth': 5, 'max_features': 'auto', 'min_samples_split': 5},\n",
       "  mean: 0.80714, std: 0.00225, params: {'max_depth': 5, 'max_features': 'auto', 'min_samples_split': 10},\n",
       "  mean: 0.80714, std: 0.00225, params: {'max_depth': 5, 'max_features': 'auto', 'min_samples_split': 20},\n",
       "  mean: 0.80714, std: 0.00225, params: {'max_depth': 5, 'max_features': 1, 'min_samples_split': 2},\n",
       "  mean: 0.80714, std: 0.00225, params: {'max_depth': 5, 'max_features': 1, 'min_samples_split': 5},\n",
       "  mean: 0.80714, std: 0.00225, params: {'max_depth': 5, 'max_features': 1, 'min_samples_split': 10},\n",
       "  mean: 0.80714, std: 0.00225, params: {'max_depth': 5, 'max_features': 1, 'min_samples_split': 20},\n",
       "  mean: 0.80714, std: 0.00225, params: {'max_depth': 5, 'max_features': 2, 'min_samples_split': 2},\n",
       "  mean: 0.80714, std: 0.00225, params: {'max_depth': 5, 'max_features': 2, 'min_samples_split': 5},\n",
       "  mean: 0.80714, std: 0.00225, params: {'max_depth': 5, 'max_features': 2, 'min_samples_split': 10},\n",
       "  mean: 0.80714, std: 0.00225, params: {'max_depth': 5, 'max_features': 2, 'min_samples_split': 20},\n",
       "  mean: 0.81041, std: 0.00528, params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2},\n",
       "  mean: 0.80878, std: 0.00548, params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 5},\n",
       "  mean: 0.80875, std: 0.00364, params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10},\n",
       "  mean: 0.80714, std: 0.00225, params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 20},\n",
       "  mean: 0.81532, std: 0.01630, params: {'max_depth': 20, 'max_features': 'auto', 'min_samples_split': 2},\n",
       "  mean: 0.81365, std: 0.00808, params: {'max_depth': 20, 'max_features': 'auto', 'min_samples_split': 5},\n",
       "  mean: 0.81852, std: 0.00879, params: {'max_depth': 20, 'max_features': 'auto', 'min_samples_split': 10},\n",
       "  mean: 0.81206, std: 0.01079, params: {'max_depth': 20, 'max_features': 'auto', 'min_samples_split': 20},\n",
       "  mean: 0.81042, std: 0.01129, params: {'max_depth': 20, 'max_features': 1, 'min_samples_split': 2},\n",
       "  mean: 0.81205, std: 0.01585, params: {'max_depth': 20, 'max_features': 1, 'min_samples_split': 5},\n",
       "  mean: 0.81366, std: 0.01286, params: {'max_depth': 20, 'max_features': 1, 'min_samples_split': 10},\n",
       "  mean: 0.80877, std: 0.00586, params: {'max_depth': 20, 'max_features': 1, 'min_samples_split': 20},\n",
       "  mean: 0.80882, std: 0.01211, params: {'max_depth': 20, 'max_features': 2, 'min_samples_split': 2},\n",
       "  mean: 0.81043, std: 0.01592, params: {'max_depth': 20, 'max_features': 2, 'min_samples_split': 5},\n",
       "  mean: 0.81522, std: 0.00818, params: {'max_depth': 20, 'max_features': 2, 'min_samples_split': 10},\n",
       "  mean: 0.80877, std: 0.00288, params: {'max_depth': 20, 'max_features': 2, 'min_samples_split': 20},\n",
       "  mean: 0.81851, std: 0.01151, params: {'max_depth': 20, 'max_features': 'log2', 'min_samples_split': 2},\n",
       "  mean: 0.81370, std: 0.01520, params: {'max_depth': 20, 'max_features': 'log2', 'min_samples_split': 5},\n",
       "  mean: 0.81370, std: 0.01520, params: {'max_depth': 20, 'max_features': 'log2', 'min_samples_split': 10},\n",
       "  mean: 0.81367, std: 0.01043, params: {'max_depth': 20, 'max_features': 'log2', 'min_samples_split': 20},\n",
       "  mean: 0.81370, std: 0.01520, params: {'max_depth': 30, 'max_features': 'auto', 'min_samples_split': 2},\n",
       "  mean: 0.81369, std: 0.01693, params: {'max_depth': 30, 'max_features': 'auto', 'min_samples_split': 5},\n",
       "  mean: 0.82016, std: 0.01206, params: {'max_depth': 30, 'max_features': 'auto', 'min_samples_split': 10},\n",
       "  mean: 0.80878, std: 0.00747, params: {'max_depth': 30, 'max_features': 'auto', 'min_samples_split': 20},\n",
       "  mean: 0.80555, std: 0.01380, params: {'max_depth': 30, 'max_features': 1, 'min_samples_split': 2},\n",
       "  mean: 0.81366, std: 0.01719, params: {'max_depth': 30, 'max_features': 1, 'min_samples_split': 5},\n",
       "  mean: 0.81527, std: 0.01336, params: {'max_depth': 30, 'max_features': 1, 'min_samples_split': 10},\n",
       "  mean: 0.80877, std: 0.00586, params: {'max_depth': 30, 'max_features': 1, 'min_samples_split': 20},\n",
       "  mean: 0.81205, std: 0.01213, params: {'max_depth': 30, 'max_features': 2, 'min_samples_split': 2},\n",
       "  mean: 0.81205, std: 0.01316, params: {'max_depth': 30, 'max_features': 2, 'min_samples_split': 5},\n",
       "  mean: 0.81361, std: 0.00524, params: {'max_depth': 30, 'max_features': 2, 'min_samples_split': 10},\n",
       "  mean: 0.80877, std: 0.00288, params: {'max_depth': 30, 'max_features': 2, 'min_samples_split': 20},\n",
       "  mean: 0.81687, std: 0.00930, params: {'max_depth': 30, 'max_features': 'log2', 'min_samples_split': 2},\n",
       "  mean: 0.81206, std: 0.01298, params: {'max_depth': 30, 'max_features': 'log2', 'min_samples_split': 5},\n",
       "  mean: 0.81532, std: 0.01630, params: {'max_depth': 30, 'max_features': 'log2', 'min_samples_split': 10},\n",
       "  mean: 0.81206, std: 0.01079, params: {'max_depth': 30, 'max_features': 'log2', 'min_samples_split': 20},\n",
       "  mean: 0.81370, std: 0.01520, params: {'max_depth': 100, 'max_features': 'auto', 'min_samples_split': 2},\n",
       "  mean: 0.81369, std: 0.01693, params: {'max_depth': 100, 'max_features': 'auto', 'min_samples_split': 5},\n",
       "  mean: 0.82016, std: 0.01206, params: {'max_depth': 100, 'max_features': 'auto', 'min_samples_split': 10},\n",
       "  mean: 0.80878, std: 0.00747, params: {'max_depth': 100, 'max_features': 'auto', 'min_samples_split': 20},\n",
       "  mean: 0.80555, std: 0.01380, params: {'max_depth': 100, 'max_features': 1, 'min_samples_split': 2},\n",
       "  mean: 0.81366, std: 0.01719, params: {'max_depth': 100, 'max_features': 1, 'min_samples_split': 5},\n",
       "  mean: 0.81527, std: 0.01336, params: {'max_depth': 100, 'max_features': 1, 'min_samples_split': 10},\n",
       "  mean: 0.80877, std: 0.00586, params: {'max_depth': 100, 'max_features': 1, 'min_samples_split': 20},\n",
       "  mean: 0.81205, std: 0.01213, params: {'max_depth': 100, 'max_features': 2, 'min_samples_split': 2},\n",
       "  mean: 0.81205, std: 0.01316, params: {'max_depth': 100, 'max_features': 2, 'min_samples_split': 5},\n",
       "  mean: 0.81361, std: 0.00524, params: {'max_depth': 100, 'max_features': 2, 'min_samples_split': 10},\n",
       "  mean: 0.80877, std: 0.00288, params: {'max_depth': 100, 'max_features': 2, 'min_samples_split': 20},\n",
       "  mean: 0.81687, std: 0.00930, params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 2},\n",
       "  mean: 0.81206, std: 0.01298, params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 5},\n",
       "  mean: 0.81532, std: 0.01630, params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 10},\n",
       "  mean: 0.81206, std: 0.01079, params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 20},\n",
       "  mean: 0.81370, std: 0.01520, params: {'max_depth': None, 'max_features': 'auto', 'min_samples_split': 2},\n",
       "  mean: 0.81369, std: 0.01693, params: {'max_depth': None, 'max_features': 'auto', 'min_samples_split': 5},\n",
       "  mean: 0.82016, std: 0.01206, params: {'max_depth': None, 'max_features': 'auto', 'min_samples_split': 10},\n",
       "  mean: 0.80878, std: 0.00747, params: {'max_depth': None, 'max_features': 'auto', 'min_samples_split': 20},\n",
       "  mean: 0.80555, std: 0.01380, params: {'max_depth': None, 'max_features': 1, 'min_samples_split': 2},\n",
       "  mean: 0.81366, std: 0.01719, params: {'max_depth': None, 'max_features': 1, 'min_samples_split': 5},\n",
       "  mean: 0.81527, std: 0.01336, params: {'max_depth': None, 'max_features': 1, 'min_samples_split': 10},\n",
       "  mean: 0.80877, std: 0.00586, params: {'max_depth': None, 'max_features': 1, 'min_samples_split': 20},\n",
       "  mean: 0.81205, std: 0.01213, params: {'max_depth': None, 'max_features': 2, 'min_samples_split': 2},\n",
       "  mean: 0.81205, std: 0.01316, params: {'max_depth': None, 'max_features': 2, 'min_samples_split': 5},\n",
       "  mean: 0.81361, std: 0.00524, params: {'max_depth': None, 'max_features': 2, 'min_samples_split': 10},\n",
       "  mean: 0.80877, std: 0.00288, params: {'max_depth': None, 'max_features': 2, 'min_samples_split': 20},\n",
       "  mean: 0.81687, std: 0.00930, params: {'max_depth': None, 'max_features': 'log2', 'min_samples_split': 2},\n",
       "  mean: 0.81206, std: 0.01298, params: {'max_depth': None, 'max_features': 'log2', 'min_samples_split': 5},\n",
       "  mean: 0.81532, std: 0.01630, params: {'max_depth': None, 'max_features': 'log2', 'min_samples_split': 10},\n",
       "  mean: 0.81206, std: 0.01079, params: {'max_depth': None, 'max_features': 'log2', 'min_samples_split': 20}],\n",
       " {'max_depth': 30, 'max_features': 'auto', 'min_samples_split': 10},\n",
       " 0.8201637624520085)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_1.fit(train[predictors],train[target])\n",
    "grid_search_1.grid_scores_, grid_search_1.best_params_, grid_search_1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Will narrow down the grid search a bit. For max_features will use 'auto'. Will add number of trees (n_estimators)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid_2 = {\n",
    "    'min_samples_split':[6,8,10,12],    \n",
    "    'max_depth':[26, 28, 30, 32, 34, None],\n",
    "    'n_estimators':[10, 50, 100, 300]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search_2 = GridSearchCV(estimator = RandomForestClassifier(random_state=1, n_jobs=-1), \n",
    "         param_grid = param_grid_2, scoring='accuracy', n_jobs=-1, iid=False, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search_2.fit(train[predictors],train[target])\n",
    "grid_search_2.grid_scores_, grid_search_2.best_params_, grid_search_2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Will test for various numbers of trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid_3 = {\n",
    "    'n_estimators':[40, 45, 50, 55, 60, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search_3 = GridSearchCV(estimator = RandomForestClassifier(max_depth=26,\n",
    "                                                                min_samples_split=10,\n",
    "                                                                random_state=1, n_jobs=-1), \n",
    "         param_grid = param_grid_3, scoring='accuracy', n_jobs=-1, iid=False, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search_3.fit(train[predictors],train[target])\n",
    "grid_search_3.grid_scores_, grid_search_3.best_params_, grid_search_3.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The optimized model has the following parameters: max_depth=26, min_samples_split=10, n_estimators=50. The other parameters has their default values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3) Let's check the model (a) with cross-validation on the train set, (b) then simply on the whole train set, (c) then on test set.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies = [ 0.81451613  0.81451613  0.81451613  0.81300813  0.8442623 ]\n",
      "mean accuracy = 0.820163762452\n"
     ]
    }
   ],
   "source": [
    "Random_Forest_model = RandomForestClassifier(max_depth=26, min_samples_split=10, \n",
    "                                             n_estimators=50, n_jobs=-1, random_state=1)\n",
    "print_scores(Random_Forest_model, train[predictors], train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89951377633711505"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model on train-set and evaluate on train set\n",
    "Random_Forest_model.fit(train[predictors], train[target])\n",
    "Random_Forest_model.score(train[predictors], train[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the model is overfitting. Thus, it is likely that it could be further optimized. In theory I should reach the point where the score on train set (where target is known) and on test set (where target is not known) are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85161290322580641"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check model on the test set\n",
    "Random_Forest_model.score(test[predictors], test[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, this model gives a higher accuracy than a majority class prediction model would give. Also, it gives a higher accuracy than the logistic regression in the previous task. However, I do not see a significant improvement, thus a higher focus should be put on feature selection and dealing with missing values. Also, it would be interesting to try some other models like XGboost or some SVM.\n",
    "It is a bit dissapointing the the model does not perform much better than majority class prediction. However, if we would focus not just on accuracy, but on other aspects like precision and recall, than perhaps it would be more useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Deal with imbalaced dataset. Out of 798 observations, response variable is 0 in 645 observations, and it is 1 in 153 cases. It is not a very big disbalance, but it is possible that prediction accuracy would be better if I would deal with this imbalancing. (a) The simplest approach is to randomly remove 492 rows where response variable is 0, this would result in a balaced dataset where we have 153 cases of response variable being 0 and 153 casee being 1. (b) A bit better approach would be to put more weight on obseravations where response is 1. Each such observation would weigh 4.2 (645/153). (c) Employ some of the many other approaches of dealing with imbalanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Columns v173, v175 and v177 contain some date information. It would be good to understand what these dates are about and then to extract some valuable features. It could be: duration, starting and end time in hours, days, months, etc. Such information could be helpful at making better predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) I am mainly removing columns with many NAs. For rows I was more conservative - I was removing only those that had all NA values except for key columns. It might be beneficial to apply a threshold and remove rows that has too many missing values (similarly as I did with columns)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "4) Use better techniques for dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Use SVM for sparse datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "6) Drop columns that has too few variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(corr_with_target_abs_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr_with_target_abs_desc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_list = ['a','b','c']\n",
    "for i, item in enumerate(tmp_list,1):\n",
    "    print('i=',i)\n",
    "    print('item=',item)\n",
    "\n",
    "print()\n",
    "for j in range(1, len(tmp_list)):\n",
    "    print(tmp_list[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corr_with_target_abs_desc[[True, True, True] + [False]*74]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr_with_target_abs_desc[my_bool_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr_with_target_abs_desc[my_bool_list].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr_with_target_abs_desc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr_with_target_abs_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_reg.fit(train[predictors], train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_reg.score(train[predictors], train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_reg.score(test[predictors], test[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_reg.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame(log_reg.coef_, columns=predictors)\n",
    "coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max(coef_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_normalized.corr()['response'].apply(np.abs).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt_plot = plt.matshow(dataset_filled.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt_fig = plt_plot.get_figure()\n",
    "plt_fig.savefig('fig_plt.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.savefig('graph_1.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pylab qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.matshow(dataset_filled.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_filled.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "corr = dataset_filled.corr()\n",
    "myplot_seaborn=sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myfig_seaborn = myplot_seaborn.get_figure()\n",
    "myfig_seaborn.savefig('fig_seaborn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "take only text columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replace ',' with '.' in floats => use regex (*[N*int','M*int])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "impute missing values!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "normalize all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one hot encoder / create dummies for text information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "train regularized regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(dataset_full_with_dummies.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_col_names_without_target(dataframe, target = target):\n",
    "    column_names_list = list(dataframe.columns)\n",
    "    if target in column_names_list:\n",
    "        column_names_list.remove(target)\n",
    "    return column_names_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_col_names_without_target(dataframe, target = target):\n",
    "    all_column_names_list = list(dataframe.columns)\n",
    "    col_names_without_target = all_column_names_list.remove[target]\n",
    "    return list(col_names_without_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mylist = ['a', 'b', 'c']\n",
    "mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mylist.remove('a')\n",
    "mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'a' in mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset_orange.domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_orange.save(\"output_dataset_orange.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_normalized.to_csv(\"output_dataset_normalized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_not_cleaned_keys_dropped.to_csv('output_dataset_full_not_cleaned_keys_dropped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set(dataset_full_with_dummies.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_with_dummies_np[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_np2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(dataset_full_np2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_np2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_np2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(dataset_full_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(dataset_full_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_0_and_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full.loc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(dataset_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_with_dummies.loc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set(dataset_full_with_dummies.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_with_dummies.to_csv('output_dataset_full_with_dummies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_time_converted.loc[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_time_converted.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_time_converted.to_csv('output_dataset_full_time_converted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_filled.to_csv('output_dataset_filled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_0.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_example = dataset_1.copy(deep=True)\n",
    "dataset_example.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataset_example = dataset_example.dropna(axis=0, how='all', subset=all_columns_no_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataset_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(dataset_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set(dataset_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list(dataset_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " df1 = pd.DataFrame({'A': ['yes', 'yes', 'no', 'maybe'],\n",
    "                        'B': ['cat1', 'cat1', 'cat2', np.nan],\n",
    "                        'C': [1.6, 5.3, 0.0, 7.3],\n",
    "                        'D': [6, 3, 2, 2]},  index=[0, 1, 2, 3])\n",
    "df1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(df1, dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'A': [1, 3, 4, 5],\n",
    "                    'B': [3.5, 6.6, 7.89, np.nan],\n",
    "                    'C': [1.6, 5.3, 0.0, 7.3],\n",
    "                    'D': [6, 3, np.nan, 2],\n",
    "                    'E': [np.nan, np.nan, np.nan, np.nan],\n",
    "                    'F': ['hello', np.nan, 'world', ''],\n",
    "                   },  index=[0, 1, 2, 3])\n",
    "df2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_nulls_in_col(col):\n",
    "    if col.dtype=='O':\n",
    "        null_count_in_col = len(col[pd.isnull(col)])\n",
    "        empty_count_in_col = len(col[col==''])\n",
    "        null_count_in_col = null_count_in_col + empty_count_in_col\n",
    "    else:\n",
    "        null_count_in_col = len(col[np.isnan(col)])\n",
    "    return null_count_in_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_nulls_in_df(df):\n",
    "    null_counts_in_cols = df.apply(count_nulls_in_col)\n",
    "    null_count_in_df = null_counts_in_cols.sum()\n",
    "    return null_count_in_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_nulls_in_col(df2['F'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_nulls_in_df(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2_np = df2.values\n",
    "df2_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({'E': [4, 3, 3, 5]})\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2['e'] = df3\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "domain = Orange.data.Domain([size, height, shape], speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df2_orange = Orange.data.Table(my_domain, df2_np)\n",
    "#df2_orange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2_orange.domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(df2_orange.domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_np = np.array([[1, 2, 3], [5, 9.8, 14.7],\n",
    "                    [2, 4, np.nan], [1, 2, 3.5], \n",
    "                    [1, 2, 3], [3, 6.1, 8.9],\n",
    "                    [2, 4, 6], [3, 5.9, np.nan],\n",
    "                    [1, 2, 3], [1, 1.8, 3.3]],)\n",
    "set_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_pd = pd.DataFrame(set_np, columns = ['A', 'B', 'C'])\n",
    "set_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_filled=set_pd.copy(deep=True)\n",
    "set_filled.fillna(set_pd.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_pd.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orange_set = Orange.data.Table(set_np)\n",
    "orange_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Orange.preprocess import Impute\n",
    "imputer = Orange.preprocess.Impute.ModelConstructor()\n",
    "imputer.learner_continuous = imputer.learner_discrete = Orange.classification.tree.TreeLearner(min_subset=20)\n",
    "#imputer.learner_continuous = Orange.ensemble.forest.RandomForestLearner\n",
    "imputer = imputer(orange_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Orange.preprocess import Impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "na_df = pd.DataFrame([[1, 7, np.nan, np.nan, np.nan], [1, 7, np.nan, np.nan, np.nan],\n",
    "                    [1, 2, 3, 4, 5], [3, 4, 5, 1, np.nan],\n",
    "                    [6, 4, 5, np.nan, np.nan], [1, 2, np.nan, np.nan, np.nan], \n",
    "                    [1, 7, np.nan, np.nan, np.nan], [1, 7, np.nan, np.nan, np.nan],\n",
    "                    [1, 7, np.nan, np.nan, np.nan], [1, 7, np.nan, np.nan, np.nan],\n",
    "                    [1, 7, np.nan, np.nan, np.nan], [1, 7, np.nan, np.nan, np.nan]],\n",
    "                    columns=['key1','A','B','C','D'])\n",
    "na_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "na_df4 = na_df.copy(deep=True)\n",
    "na_df4 = drop_rows_and_cols_with_NA_below_thresholds(na_df4, key_names=key_names, col_thresh=0.1, row_thresh=0.6).loc[:100]\n",
    "na_df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "na_df4 = na_df.copy(deep=True)\n",
    "na_df4 = na_df4.dropna(axis=1, thresh=1) # droping NA columns\n",
    "na_df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "na_df2=na_df.copy(deep=True)\n",
    "na_df2 = na_df2.dropna(axis=0, how='all',subset={'B','C','A'})\n",
    "na_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "na_df_columns = list(na_df.columns)\n",
    "na_df_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "na_df_columns_set=set(na_df_columns)\n",
    "na_df_columns_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(na_df_columns_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set(na_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "na_df3=na_df.copy(deep=True)\n",
    "drop_NA_only_columns_and_rows(na_df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[1,2,3] - [1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set([1,2,3]) - set([1,2,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#old drop NA function v1\n",
    "def drop_NA_only_columns_and_rows(input_df, key_names=key_names):\n",
    "    df = input_df.copy(deep=True)\n",
    "    df_columns = set(df)\n",
    "    df_columns_without_keys = df_columns - set(key_names)\n",
    "    df = df.dropna(axis=0, how='all', subset=df_columns_without_keys) # droping rows that have all NA values except for keys\n",
    "    df = df.dropna(axis=1, how='all') # droping NA columns\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#old drop NA function v2\n",
    "def drop_rows_with_NA_only_and_cols_with_NA_below_threshold(input_df, key_names=key_names, threshold_percent=0.20):\n",
    "    df = input_df.copy(deep=True)\n",
    "    \n",
    "    df_columns = set(df)\n",
    "    df_columns_without_keys = df_columns - set(key_names)\n",
    "    df = df.dropna(axis=0, how='all', subset=df_columns_without_keys) # droping rows that have all NA values except for keys\n",
    "    \n",
    "    number_of_rows = len(df)\n",
    "    threshold_integer = round(threshold_percent * number_of_rows)\n",
    "    df = df.dropna(axis=1, thresh=threshold_integer) # droping columns that have non-NA cell count is below threshold\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#old with regex\n",
    "#function to replace ',' with '.'\n",
    "#import re\n",
    "def replace_commas_with_dots_in_string(single_string):\n",
    "    if type(single_string) == str:\n",
    "        ##df = input_dataframe.copy(deep=True)\n",
    "        ##regex_input = '^[0-9]+,[0-9]+$'\n",
    "        ##regex_output = '^[0-9]+\\.[0-9]+$'\n",
    "        ##single_string = re.sub('^[0-9]+,[0-9]+$', '^[0-9]+\\.[0-9]+$', single_string)\n",
    "        ##df.replace(to_replace=regex_input, value=regex_output, regex=True)\n",
    "        single_string = single_string.replace(',','.')\n",
    "    return single_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(dataset_full_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_names_no_key_no_target = get_col_names_without_target_and_keys(dataset_full_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_clean[col_names_no_key_no_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_clean[col_names_no_key_no_target].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_clean[col_names_no_key_no_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_names_no_key_no_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_clean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_clean['v4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_clean['v12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "na_df = pd.DataFrame([[1.5, \"2,5\", 3, 4, 5], [3.5, 4.5, 5, 1, np.nan],\n",
    "                    [6, \"4,4\", 5, \"text with 4,5\", \"4,5 another text\"], [1, 2, np.nan, np.nan, np.nan]],\n",
    "                    columns=['key1','A','B','C','D'])\n",
    "na_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "na_df = na_df.applymap(replace_commas_with_dots_in_string)\n",
    "na_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "na_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "na_df = na_df.applymap(convert_floats_in_string_to_floats)\n",
    "na_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "na_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replace_commas_with_dots_in_df(na_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "na_df.replace(\",\",\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "na_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "na_df.drop('B', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "na_df = na_df.drop(['A','B'], axis=1)\n",
    "na_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "na_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full.to_csv('output_dataset_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_full.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int(5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_not_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_string_only = dataset_full.select_dtypes(include=['object']).copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_string_only.drop(['v173','v175','v177'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_string_only = df_string_only.drop(['v173','v175','v177'], axis=1).copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_string_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(df_string_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame([['A', \"B\", 'YES', 4, 5], ['A', \"B\", 'YES', 1, np.nan],\n",
    "                    ['C', \"D\", 'NO', 5, 4], ['C',np.nan, 'NO', np.nan, np.nan]],\n",
    "                    columns=['col1','col2','col3','col4','col5'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(df1, dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1[[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.core.dtypes.common.is_datetime_or_timedelta_dtype(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.core.dtypes.common.is_datetime64_ns_dtype(dates)|pd.core.dtypes.common.is_timedelta64_ns_dtype(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.to_datetime(dates, errors='raise', dayfirst=False, yearfirst=False, utc=None, box=True, format=None, exact=True, unit=None, infer_datetime_format=False, origin='unix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fake_dates = dataset_full['v197'].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fake_dates.loc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#old\n",
    "def get_col_names_without_target_and_keys(dataframe, key_names = key_names, target = target):\n",
    "    all_column_names_set = set(dataframe)\n",
    "    col_names_without_target_and_keys = all_column_names_set - set(key_names) - set([target])\n",
    "    return list(col_names_without_target_and_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def check_if_date(element):\n",
    "    if type(element) == str:\n",
    "        ##df = input_dataframe.copy(deep=True)\n",
    "        ##regex_input = '^[0-9]+,[0-9]+$'\n",
    "        ##regex_output = '^[0-9]+\\.[0-9]+$'\n",
    "        ##single_string = re.sub('^[0-9]+,[0-9]+$', '^[0-9]+\\.[0-9]+$', single_string)\n",
    "        ##df.replace(to_replace=regex_input, value=regex_output, regex=True)\n",
    "        single_string = single_string.replace(',','.')\n",
    "    return single_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Python uses '.' as a decimal point. However, in datasets sometimes we get ',' as a decimal point. Need to replace ',' with '.'. After this is done, will need to convert floats stored as string to Python floats. Integer columns will also be converted to floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_commas_with_dots_in_string(single_string):\n",
    "    if type(single_string) == str:\n",
    "        single_string = single_string.replace(',','.')\n",
    "    return single_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# applying a function on each cell of a dataframe\n",
    "dataset_full = dataset_full.applymap(replace_commas_with_dots_in_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to convert floats stored as string to floats\n",
    "def convert_floats_in_string_to_floats(element):\n",
    "    if type(element) == str or type(element) == int:\n",
    "        try:\n",
    "            return float(element)\n",
    "        except (ValueError, TypeError):\n",
    "            return element\n",
    "    return element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not want to convert key and response columns to float, so need to obtain a list of all columns except for keys and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_to_convert = get_col_names_without_target_and_keys(dataset_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting all columns except for keys and response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full.loc[:,columns_to_convert] = (dataset_full[columns_to_convert]).applymap(convert_floats_in_string_to_floats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.to_datetime(dataset_full_copy, format='%Y-%m-%d %H:%M', errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.to_datetime(500, format='%Y-%m-%d %H:%M', errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.to_datetime(date, format='%Y-%m-%d %H:%M', errors='ignore').loc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date = dataset_full['v173'].copy(deep=True)\n",
    "date.loc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#old\n",
    "def col_to_datetime(input_col):\n",
    "    if input_col.dtype=='O':\n",
    "        col=pd.to_datetime(input_col, format='%Y-%m-%d %H:%M', errors='ignore')\n",
    "        return col\n",
    "    else:\n",
    "        return input_col    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "def col_to_datetime(input_col):\n",
    "    if input_col.dtype=='O': #in pandas dataframe columns containing Strings, has type Object, or 'O'\n",
    "        col_datetime=pd.to_datetime(input_col, format='%Y-%m-%d %H:%M', errors='ignore') #convert to datetime only if format is '%Y-%m-%d %H:%M'\n",
    "        if col_datetime.dtype=='datetime64[ns]': \n",
    "            epoch_timestamp_col = col_datetime - dt.datetime(1970, 1, 1)\n",
    "            sec_float_col = epoch_timestamp_col / np.timedelta64(1, 's')\n",
    "            return sec_float_col\n",
    "        return col_datetime\n",
    "    else:\n",
    "        return input_col           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates.loc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates2=dates.apply(col_to_datetime)\n",
    "dates2.loc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(dates2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "dates3=dataset_full_copy.apply(col_to_datetime)\n",
    "dates3.loc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates3.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_copy.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates = dataset_full[['v173','v175','v177']].copy(deep=True)\n",
    "dates.loc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full_copy = dataset_full.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#old - removed because Orange does not have imputation library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "(a) In Pandas, Numpy and Scikit learn packages there is no possibility to impute missing values with machine learning algorithms (e.g. to predict value). For that I would need to use Orange package. But to use that package I would need to tranform dataframes from Pandas to Orange.\n",
    "\n",
    "_Note: Both Pandas and Orange dataframes are just wrapers for NumPay, so doing this transformation is not computationally expensive._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2 functions to convert Pandas dataframe to Orange table/dataframe\n",
    "def get_feature_description_for_orange_from_pandas(pandas_df):\n",
    "    feature_list = [Orange.data.ContinuousVariable(col) for col in list(pandas_df.columns)]\n",
    "    return Domain(feature_list)\n",
    "\n",
    "def pandas_to_orange_df(pandas_df):\n",
    "    np_array = pandas_df.values\n",
    "    orange_table_domain = get_feature_description_for_orange_from_pandas(pandas_df)\n",
    "    orange_table = Orange.data.Table(orange_table_domain, np_array)\n",
    "    return orange_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_orange = pandas_to_orange_df(dataset_full_with_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_full[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_string_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full['response'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full['response'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(dataset_full.nunique().columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(dataset_full.nunique().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(dataset_full.nunique().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_counts_in_string_cols_series = dataset_full_clean.select_dtypes(include=[object]).nunique()\n",
    "unique_counts_in_string_cols_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_counts_in_string_cols_series[unique_counts_in_string_cols_series>100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#copy\n",
    "def remove_string_cols_with_unique_value_count_over_threshold(input_df, unique_count_threshold = 20):\n",
    "    df = input_df.copy(deep=True)\n",
    "    unique_counts_in_string_cols_series = df.select_dtypes(include=[object]).nunique() #string is 'object' type\n",
    "    string_cols_over_threshold_series = unique_counts_in_string_cols_series[unique_counts_in_string_cols_series>unique_count_threshold]\n",
    "    list_of_string_cols_over_threshold = list(string_cols_over_threshold_series.keys())\n",
    "    df = df.drop(list_of_string_cols_over_threshold, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_with_some_string_cols_removed = remove_string_cols_with_unique_value_count_over_threshold(dataset_full_clean, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_with_some_string_cols_removed.to_csv('df_with_some_string_cols_removed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_full.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " dataset_full.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#old\n",
    "def exclude_similar_features_and_get_unique(corr_with_target_series, similarity_param = 0.000001):\n",
    "    exclusion_boolean_list = [True] # first item not to be excluded\n",
    "    for i in range(1, len(corr_with_target_series)):\n",
    "        #print(i,')')\n",
    "        #print('corr_with_target_series[i] =',corr_with_target_series[i])\n",
    "        #print('corr_with_target_series[i-1] =',corr_with_target_series[i-1])\n",
    "        if np.isnan(corr_with_target_series[i]):\n",
    "            exclusion_boolean_list.append(False)\n",
    "            #print('is NAN')\n",
    "        elif (corr_with_target_series[i-1] - corr_with_target_series[i])<=similarity_param:\n",
    "            exclusion_boolean_list.append(False)\n",
    "            #print('similar')\n",
    "        else:\n",
    "            exclusion_boolean_list.append(True)\n",
    "            #print('not_similar')\n",
    "    unique_features = list(corr_with_target_series[exclusion_boolean_list].index)\n",
    "    #print()\n",
    "    #print(boolean_list)\n",
    "    #print()\n",
    "    #print(len(boolean_list))\n",
    "    #print()\n",
    "    #print(len(corr_with_target_series))\n",
    "    return unique_features\n",
    "    #return boolean_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,10))\n",
    "\n",
    "x_labels = list(top15_coef.keys()) #[2,4,3,6,1,7]\n",
    "y = list(top15_coef.values)\n",
    "\n",
    "#ax[0].plot(x, y)\n",
    "\n",
    "ax.plot(range(len(y)),y)\n",
    "#ax.set_xticklabels(['empty']+x)\n",
    "ax.set_xticks(range(len(y)),x_labels)\n",
    "#ax.set_xticklabels(x_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "star = mpath.Path.unit_regular_star(6)\n",
    "circle = mpath.Path.unit_circle()\n",
    "# concatenate the circle with an internal cutout of the star\n",
    "verts = np.concatenate([circle.vertices, star.vertices[::-1, ...]])\n",
    "codes = np.concatenate([circle.codes, star.codes])\n",
    "cut_star = mpath.Path(verts, codes)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,10))\n",
    "\n",
    "x = list(top15_coef.keys()) \n",
    "y = list(top15_coef.values) \n",
    "\n",
    "ax.plot(np.arange(0, len(x), 1), y) #, '--r', marker=cut_star, markersize=15)\n",
    "#ax.plot(x, y)\n",
    "#ax.set_xticklabels(['empty']+x)\n",
    "#ax.set_xticklabels(x)\n",
    "ax.set_xticks(set(x))\n",
    "\n",
    "ax.grid(color='g', linestyle='-', linewidth=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "star = mpath.Path.unit_regular_star(6)\n",
    "circle = mpath.Path.unit_circle()\n",
    "# concatenate the circle with an internal cutout of the star\n",
    "verts = np.concatenate([circle.vertices, star.vertices[::-1, ...]])\n",
    "codes = np.concatenate([circle.codes, star.codes])\n",
    "cut_star = mpath.Path(verts, codes)\n",
    "\n",
    "\n",
    "plt.plot(list(top15_coef.keys()), top15_coef.values,  '--r', marker=cut_star, markersize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "star = mpath.Path.unit_regular_star(6)\n",
    "circle = mpath.Path.unit_circle()\n",
    "# concatenate the circle with an internal cutout of the star\n",
    "verts = np.concatenate([circle.vertices, star.vertices[::-1, ...]])\n",
    "codes = np.concatenate([circle.codes, star.codes])\n",
    "cut_star = mpath.Path(verts, codes)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,4))\n",
    "x = ['f', 'b', 'c', 'e', 'a']\n",
    "y = [1, 2, 3, 6, 8]\n",
    "\n",
    "ax.set_xticklabels(['f', 'b', 'c', 'e', 'a'])\n",
    "ax.plot(np.arange(5), y, '--r', marker=cut_star, markersize=15)\n",
    "\n",
    "#fig.show()\n",
    "\n",
    "#plt.plot(x, y, '--r', marker=cut_star, markersize=15)\n",
    "#plt.axis.set_xticklabels(['f', 'b', 'c', 'e', 'a'])\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(['f', 'b', 'c', 'd'], [1,2,3,4], 'ro')\n",
    "#plt.axis([0, 6, 0, 10])\n",
    "plt.axis.set_xticklabels(['zero', 'f', 'b', 'c', 'e', 'a'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
    "\n",
    "x = ['x','b','c','d','e','f'] #[2,4,3,6,1,7]\n",
    "y = [1,2,3,4,5,10]\n",
    "\n",
    "ax[0].plot(x, y)\n",
    "\n",
    "ax[1].plot(np.arange(1, len(x)+1), y)\n",
    "ax[1].set_xticklabels(['empty']+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,4))\n",
    "\n",
    "x = ['x','b','c','d','e','f'] #[2,4,3,6,1,7]\n",
    "y = [1,2,3,4,5,10]\n",
    "\n",
    "#ax[0].plot(x, y)\n",
    "\n",
    "ax.plot(np.arange(1, len(x)+1), y)\n",
    "ax.set_xticklabels(['empty']+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top15_coef.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(top15_coef.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuple(top15_coef.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(top15_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top15_coef.axes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top15_coef.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top15_coef.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#uncomment for testing with small datasets\n",
    "#name_dataset_0 = 'small_app_dataset.csv' # 'app_dataset.csv'\n",
    "name_dataset_1 = 'small_dataset_1.csv' # 'dataset_1.csv'\n",
    "name_dataset_2 = 'small_dataset_2.csv' # 'dataset_2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#old one\n",
    "def exclude_similar_features_and_get_unique(corr_with_target_series, similarity_param = 0.000001):\n",
    "    exclusion_boolean_list = [True] # first item not to be excluded\n",
    "    for i in range(1, len(corr_with_target_series)):\n",
    "        if np.isnan(corr_with_target_series[i]):\n",
    "            exclusion_boolean_list.append(False)\n",
    "        elif (corr_with_target_series[i-1] - corr_with_target_series[i])<=similarity_param:\n",
    "            exclusion_boolean_list.append(False)\n",
    "        else:\n",
    "            exclusion_boolean_list.append(True)\n",
    "    unique_features = list(corr_with_target_series[exclusion_boolean_list].index)\n",
    "    return unique_features\n",
    "\n",
    "\n",
    "#use tail method, substract and other methods from pandas.series\n",
    "#or use unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exclude_similar_features_and_get_unique(corr_with_target_series, similarity_thresh = 0.000001):\n",
    "    #getting 2 arrays from series - 1 array without the first element, and another without the last element\n",
    "    corr_with_target_array_less_first_el = corr_with_target_series.tail(len(corr_with_target_series)-1).values\n",
    "    corr_with_target_array_less_last_el = corr_with_target_series.head(len(corr_with_target_series)-1).values\n",
    "    \n",
    "    #calculating absoluste differences between these arrays, which is equivalent to finding difference between\n",
    "    #subsequent elements in the original series\n",
    "    corr_with_target_array_subseq_el_differences = np.abs(\n",
    "            corr_with_target_array_less_first_el - corr_with_target_array_less_last_el)\n",
    "    \n",
    "    #finding which elements has differences over similarity_thresh\n",
    "    corr_with_target_array_subseq_el_differences_over_thresh = (\n",
    "            corr_with_target_array_subseq_el_differences > similarity_thresh )\n",
    "    \n",
    "    #we will keep the first element, so assume set it to True to keep\n",
    "    first_el_diff = np.array([True])\n",
    "    corr_with_target_array_subseq_el_differences_over_thresh = np.append(\n",
    "            first_el_diff, corr_with_target_array_subseq_el_differences_over_thresh)\n",
    "    \n",
    "    #geetting boolean list that shows which elements are unique and thus should stay and which to be excluded\n",
    "    corr_with_target_array_subseq_el_differences_over_thresh_bool_list = list(\n",
    "            corr_with_target_array_subseq_el_differences_over_thresh)\n",
    "    \n",
    "    #getting a list of unique features\n",
    "    corr_with_target_series_unique = (\n",
    "            corr_with_target_series[corr_with_target_array_subseq_el_differences_over_thresh_bool_list])\n",
    "    unique_feature_list = list(corr_with_target_series_unique.index)\n",
    "    return unique_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_similar_features_and_get_unique2(corr_with_target_series, similarity_param = 0.000001):\n",
    "    corr_with_target_array_less_first_el = corr_with_target_series.tail(len(corr_with_target_series)-1).values\n",
    "    #print(corr_with_target_array_less_first_el)\n",
    "    corr_with_target_array_less_last_el = corr_with_target_series.head(len(corr_with_target_series)-1).values\n",
    "    #print(corr_with_target_array_less_last_el)\n",
    "    corr_with_target_array_subseq_el_differences = np.abs(\n",
    "            corr_with_target_array_less_first_el - corr_with_target_array_less_last_el)\n",
    "    #print(corr_with_target_array_subseq_el_differences)\n",
    "    corr_with_target_array_subseq_el_differences_over_thresh = (\n",
    "            corr_with_target_array_subseq_el_differences > similarity_param )\n",
    "    #print(corr_with_target_array_subseq_el_differences_over_thresh)\n",
    "    first_el_diff = np.array([True])\n",
    "    corr_with_target_array_subseq_el_differences_over_thresh = np.append(\n",
    "            first_el_diff, corr_with_target_array_subseq_el_differences_over_thresh)\n",
    "    #print(corr_with_target_array_subseq_el_differences_over_thresh)\n",
    "    corr_with_target_array_subseq_el_differences_over_thresh_bool_list = list(\n",
    "            corr_with_target_array_subseq_el_differences_over_thresh)\n",
    "    #print(corr_with_target_array_subseq_el_differences_over_thresh_bool_list)\n",
    "    corr_with_target_series_unique = (\n",
    "            corr_with_target_series[corr_with_target_array_subseq_el_differences_over_thresh_bool_list])\n",
    "    unique_feature_list = list(corr_with_target_series_unique.index)\n",
    "    return unique_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['response',\n",
       " 'v192',\n",
       " 'v29',\n",
       " 'v204_wifi',\n",
       " 'v204_business',\n",
       " 'v204_cellular',\n",
       " 'v204_residential',\n",
       " 'v002',\n",
       " 'v182',\n",
       " 'v120',\n",
       " 'v177',\n",
       " 'v172.1_n',\n",
       " 'v174',\n",
       " 'v173',\n",
       " 'v195_low',\n",
       " 'v172.1_y',\n",
       " 'v201_moderate risk',\n",
       " 'v181',\n",
       " 'v204_mobile',\n",
       " 'v178_certified',\n",
       " 'v180',\n",
       " 'v193_yes',\n",
       " 'v178_validdomain',\n",
       " 'v183',\n",
       " 'v184_lower fraud risk',\n",
       " 'v176',\n",
       " 'v186_fraud score 101 to 300',\n",
       " 'v178_verified',\n",
       " 'v195_moderate',\n",
       " 'v185',\n",
       " 'v14',\n",
       " 'v204_dialup',\n",
       " 'v001',\n",
       " 'v175',\n",
       " 'v5',\n",
       " 'v184_data entry review',\n",
       " 'v203_nan',\n",
       " 'v172.1_p',\n",
       " 'v172.1_u',\n",
       " 'v4',\n",
       " 'v186_fraud score 1 to 100',\n",
       " 'v201_moderate by proxy reputation and country code',\n",
       " 'v204_nan',\n",
       " 'v204_wired',\n",
       " 'v184_moderate fraud risk',\n",
       " 'v123']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilja.surikovs\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in greater\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['response',\n",
       " 'v192',\n",
       " 'v29',\n",
       " 'v204_wifi',\n",
       " 'v204_business',\n",
       " 'v204_cellular',\n",
       " 'v204_residential',\n",
       " 'v002',\n",
       " 'v182',\n",
       " 'v120',\n",
       " 'v177',\n",
       " 'v172.1_n',\n",
       " 'v174',\n",
       " 'v173',\n",
       " 'v195_low',\n",
       " 'v172.1_y',\n",
       " 'v201_moderate risk',\n",
       " 'v181',\n",
       " 'v204_mobile',\n",
       " 'v178_certified',\n",
       " 'v180',\n",
       " 'v193_yes',\n",
       " 'v178_validdomain',\n",
       " 'v183',\n",
       " 'v184_lower fraud risk',\n",
       " 'v176',\n",
       " 'v186_fraud score 101 to 300',\n",
       " 'v178_verified',\n",
       " 'v195_moderate',\n",
       " 'v185',\n",
       " 'v14',\n",
       " 'v204_dialup',\n",
       " 'v001',\n",
       " 'v175',\n",
       " 'v5',\n",
       " 'v184_data entry review',\n",
       " 'v203_nan',\n",
       " 'v172.1_p',\n",
       " 'v172.1_u',\n",
       " 'v4',\n",
       " 'v186_fraud score 1 to 100',\n",
       " 'v201_moderate by proxy reputation and country code',\n",
       " 'v204_nan',\n",
       " 'v204_wired',\n",
       " 'v184_moderate fraud risk',\n",
       " 'v123']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_features2 = exclude_similar_features_and_get_unique(corr_with_target_abs_desc)\n",
    "unique_features2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_features2==unique_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_features2)==len(unique_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['response', 'v192', 'v29', 'v204_wifi', 'v204_business']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_features2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['response', 'v192', 'v29', 'v204_wifi', 'v204_business']"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_features[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3]\n",
      "[1 2]\n",
      "[1 1]\n",
      "[ True  True]\n",
      "[ True  True  True]\n",
      "[True, True, True]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude_similar_features_and_get_unique2(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2.0\n",
       "1    5.0\n",
       "2    NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = pd.Series([2, 5, np.nan])\n",
    "s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "2    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3>3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    3.0\n",
       "2    NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3-s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = pd.Series([1, 2, 3])\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_el = pd.Series([True])\n",
    "first_el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1     True\n",
       "2    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1<=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    4\n",
       "2    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2 = pd.Series([1, 4, 2])\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1_head = s1.head(len(s1)-1)\n",
    "s1_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2\n",
       "2    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1_tail=s1.tail(len(s1)-1)\n",
    "s1_tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    0.0\n",
       "2    NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(s1_head-s1_tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    0.0\n",
       "2    NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1_head-s1_tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2], dtype=int64)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1_head_np = s1.head(len(s1)-1).values\n",
    "s1_head_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3], dtype=int64)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1_tail_np=s1.tail(len(s1)-1).values\n",
    "s1_tail_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False], dtype=bool)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(s1_head_np-s1_tail_np)>2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
